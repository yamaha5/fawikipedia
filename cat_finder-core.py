#!/usr/bin/python
from __future__ import unicode_literals
# -*- coding: utf-8  -*-
# # Reza (User:yamaha5) 
# Distributed under the terms of the CC-BY-SA 3.0 .
# -*- coding: utf-8 -*-
#-------------------------------
#male (Q6581097), female (Q6581072)
#, intersex (Q1097630), transgender female (Q1052281)
#, transgender male (Q2449503), genderqueer (Q48270); 
#for animals use male animal (Q44148)
# or female animal (Q43445)
#---------------------------
#grep -i wbtime */*.py

import pywikibot,calverter, time
from pywikibot import pagegenerators
from pywikibot import config
from scripts  import calverter
import string,codecs,re,cosmetic_changes
from pywikibot.compat import query
from datetime import datetime
import fa_cosmetic_changes_core
pywikibot.config.put_throttle = 0
pywikibot.config.maxthrottle = 0
cal = calverter.Calverter()
#---------------------------
version=u'۱۵.۰۶'
Url=u'/home/reza/pycore/'
Url=u'/data/project/rezabot/pycore/scripts/'
#--------------------------
countries={u"iran":u"ایران",u"Iran":u"ایران",u"جمهوری اسلامی ایران":u"ایران",u"ایران":u"ایران",u"آمریکا":u"ایالات متحده آمریکا",u"ایالات متحده":u"ایالات متحده آمریکا",u"Abkhazia":u"آبخاز",
    u"Argentina":u"آرژانتین",u"Armenia":u"ارمنستان",u"Australia":u"استرالیا",u"Austria":u"اتریش",u"Azerbaijan":u"جمهوری آذربایجان",u"Bahamas":u"باهاما",u"Bahrain":u"بحرین",u"Bangladesh":u"بنگلادش",u"Barbados":u"باربادوس",u"Belarus":u"بلاروس",u"Belgium":u"بلژیک",u"Belize":u"بلیز",u"Benin":u"بنین",u"Bhutan":u"پادشاهی بوتان",u"Bolivia":u"بولیوی",u"Bosnia and Herzegovina":u"بوسنی و هرزگوین",
    u"Botswana":u"بوتسوانا",u"Brazil":u"برزیل",u"Brunei":u"برونئی",u"Bulgaria":u"بلغارستان",u"Burkina Faso":u"بورکینافاسو",u"Burma":u"میانمار",u"Burundi":u"بوروندی",u"Cambodia":u"کامبوج",u"Cameroon":u"کامرون",u"Canada":u"کانادا",u"Cape Verde":u"کیپ ورد",u"Central African Republic":u"جمهوری آفریقای مرکزی",u"Chad":u"چاد",u"Chile":u"شیلی",u"China":u"جمهوری خلق چین",
    u"Colombia":u"کلمبیا",u"Comoros":u"مجمع‌الجزایر قمر",u"Congo, Democratic Republic of the":u"جمهوری دموکراتیک کنگو",u"Congo, Republic of the":u"جمهوری کنگو",u"Cook Islands":u"جزایر کوک",u"Costa Rica":u"کاستاریکا",u"Croatia":u"کرواسی",u"Cuba":u"کوبا",u"Cyprus":u"قبرس",u"Czech Republic":u"جمهوری چک",u"Denmark":u"دانمارک",u"Djibouti":u"جیبوتی",
    u"Dominica":u"دومینیکا",u"Dominican Republic":u"جمهوری دومینیکن",u"East Timor":u"تیمور شرقی",u"Ecuador":u"اکوادور",u"Egypt":u"مصر",u"El Salvador":u"السالوادور",u"Equatorial Guinea":u"گینه استوایی",u"Eritrea":u"اریتره",u"Estonia":u"استونی",u"Ethiopia":u"اتیوپی",u"Fiji":u"فیجی",u"Finland":u"فنلاند",u"France":u"فرانسه",u"Gabon":u"گابن",u"Gambia":u"گامبیا",u"Georgia":u"گرجستان",
    u"Germany":u"آلمان",u"Ghana":u"غنا",u"Greece":u"یونان",u"Grenada":u"گرنادا",u"Guatemala":u"گواتمالا",u"Guinea":u"گینه",u"Guinea-Bissau":u"گینه بیسائو",u"Guyana":u"گویان",u"Haiti":u"هائیتی",u"Honduras":u"هندوراس",u"Hungary":u"مجارستان",u"Iceland":u"ایسلند",u"India":u"هند",u"Indonesia":u"اندونزی",u"Iraq":u"عراق",
    u"Ireland":u"جزیره ایرلند",u"Israel":u"اسرائیل",u"Italy":u"ایتالیا",u"Ivory Coast":u"ساحل عاج",u"Jamaica":u"جامائیکا",u"Japan":u"ژاپن",u"Jordan":u"اردن",u"Kazakhstan":u"قزاقستان",u"Kenya":u"کنیا",u"Kiribati":u"کیریباتی",u"Korea North":u"کره شمالی",u"Korea South":u"کره جنوبی",u"Kosovo":u"کوزوو",u"Kuwait":u"کویت",u"Kyrgyzstan":u"قرقیزستان",u"Laos":u"لائوس",
    u"Latvia":u"لتونی",u"Lebanon":u"لبنان",u"Lesotho":u"لسوتو",u"Liberia":u"لیبریا",u"Libya":u"لیبی",u"Liechtenstein":u"لیختن‌اشتاین",u"Lithuania":u"لیتوانی",u"Luxembourg":u"لوکزامبورگ",u"Macedonia":u"مقدونیه",u"Madagascar":u"ماداگاسکار",u"Malawi":u"مالاوی",u"Malaysia":u"مالزی",u"Maldives":u"مالدیو",u"Mali":u"مالی",u"Malta":u"مالت",u"Marshall Islands":u"جزایر مارشال",
    u"Mauritania":u"موریتانی",u"Mauritius":u"موریس",u"Mexico":u"مکزیک",u"Micronesia":u"میکرونزی",u"Moldova":u"مولداوی",u"Monaco":u"موناکو",u"Mongolia":u"مغولستان",u"Montenegro":u"مونته‌نگرو",u"Morocco":u"مراکش",u"Mozambique":u"موزامبیک",u"Nagorno-Karabakh":u"ناگورنو قره‌باغ",u"Namibia":u"نامیبیا",u"Nauru":u"نائورو",u"Nepal":u"نپال",u"Netherlands":u"هلند",
    u"New Zealand":u"نیوزیلند",u"Nicaragua":u"نیکاراگوئه",u"Niger":u"نیجر",u"Nigeria":u"نیجریه",u"Niue":u"نیووی",u"Northern Cyprus":u"جمهوری ترک قبرس شمالی",u"Norway":u"نروژ",u"Oman":u"عمان",u"Pakistan":u"پاکستان",u"Palau":u"پالائو",u"Palestine":u"فلسطین",u"Panama":u"پاناما",u"Papua New Guinea":u"پاپوآ گینه نو",u"Paraguay":u"پاراگوئه",
    u"Peru":u"پرو",u"Philippines":u"فیلیپین",u"Poland":u"لهستان",u"Portugal":u"پرتغال",u"Qatar":u"قطر",u"Romania":u"رومانی",u"Russia":u"روسیه",u"Rwanda":u"رواندا",u"SADR":u"جمهوری دموکراتیک عربی صحرا",u"Saint Kitts and Nevis":u"سنت کیتس و نویس",u"Saint Lucia":u"سنت لوسیا",u"Saint Vincent and the Grenadines":u"سنت وینسنت و گرنادین‌ها",
    u"Samoa":u"ساموآ",u"San Marino":u"سن مارینو",u"São Tomé and Príncipe":u"سائوتومه و پرینسیپ",u"Saudi Arabia":u"عربستان سعودی",u"Senegal":u"سنگال",u"Serbia":u"صربستان",u"Seychelles":u"سیشل",u"Sierra Leone":u"سیرالئون",u"Singapore":u"سنگاپور",u"Slovakia":u"اسلواکی",u"Slovenia":u"اسلوونی",u"Solomon Islands":u"جزایر سلیمان",u"Somalia":u"سومالی",u"Somaliland":u"سومالی‌لند",u"South Africa":u"آفریقای جنوبی",u"South Ossetia":u"اوستیای جنوبی",
    u"South Sudan":u"سودان جنوبی",u"Spain":u"اسپانیا",u"Sri Lanka":u"سری‌لانکا",u"Sudan":u"سودان",u"Suriname":u"سورینام",u"Swaziland":u"سوازیلند",u"Sweden":u"سوئد",u"Switzerland":u"سوئیس",u"Syria":u"سوریه",u"Taiwan":u"تایوان",u"Tajikistan":u"تاجیکستان",u"Tanzania":u"تانزانیا",u"Thailand":u"تایلند",u"Togo":u"توگو",u"Tonga":u"تونگا",u"Transnistria":u"ترنسنیستریا",
    u"Trinidad and Tobago":u"ترینیداد و توباگو",u"Tunisia":u"تونس",u"Turkey":u"ترکیه",u"Turkmenistan":u"ترکمنستان",u"Tuvalu":u"تووالو",u"Uganda":u"اوگاندا",u"Ukraine":u"اوکراین",u"United Arab Emirates":u"امارات متحده عربی",u"United Kingdom":u"بریتانیا",u"United States":u"ایالات متحده آمریکا",u"Uruguay":u"اروگوئه",u"Uzbekistan":u"ازبکستان",u"Vanuatu":u"وانواتو",u"Vatican City":u"واتیکان",u"Venezuela":u"ونزوئلا",u"Vietnam":u"ویتنام",
    u"Yemen":u"یمن",u"Zambia":u"زامبیا",u"Zimbabwe":u"زیمبابوه",u"Cook Islands":u"جزایر کوک",u"Kosovo":u"کوزوو",u"Nagorno-Karabakh":u"ناگورنو قره‌باغ",u"Niue":u"نیووی",u"Northern Cyprus":u"جمهوری ترک قبرس شمالی",u"Sahrawi Arab Democratic Republic":u"جمهوری دموکراتیک عربی صحرا",u"Somaliland":u"سومالی‌لند",u"South Ossetia":u"اوستیای جنوبی",u"Sudan, South":u"سودان جنوبی",u"Taiwan (Republic of China)":u"تایوان",u"Transnistria":u"ترنسنیستریا",
    u"China, Republic of":u"تایوان",u"Côte d'Ivoire":u"ساحل عاج",u"Ivory Coast":u"ساحل عاج",u"Democratic People's Republic of Korea":u"کره شمالی",u"Democratic Republic of the Congo":u"جمهوری دموکراتیک کنگو",u"Holy See":u"سریر مقدس",u"Myanmar":u"میانمار",u"North Korea":u"کره شمالی",u"Pridnestrovie":u"ترنسنیستریا",u"Republic of Korea":u"کره جنوبی",u"Republic of the Congo":u"جمهوری کنگو",u"South Korea":u"کره جنوبی",u"Timor-Leste":u"تیمور شرقی"
    }
Male_Names=[u"عبیدالله",u"آتیلا",u"آخوند",u"آذرباد",u"آذرتاش",u"آذرخش",u"آراد",u"آراز",u"آرامائیس",u"آراکل",u"آربی",u"آرتان",u"آرتم",u"آرداشس",u"آرسن",u"آرشام",u"آرشاک",u"آرش",u"آرمان",u"آرمن",u"آرمین",u"آرن",u"آرکادی",u"آریا",u"آریل",u"آرین",u"آریوبرزن",u"آزادبه",u"آزاد",u"آصف",u"آغامحمدخان",u"آفریغ",u"آقابزرگ",u"آقاخان",u"آقاعلی",u"آقامحمد",u"آقانورالدین",u"آقا",u"آق‌سرایی",u"آلاپالاز",u"آلفرد",u"آلکو",u"آلک",u"آنتوان",u"آندرانیک",u"آندره",u"آنوش",u"آوانس",u"آوتيس",u"آودیس",u"آگاه",u"آیت",u"آیدین",u"آی‌محمد",u"اباصلت",u"ابراهیم‌خان",u"ابراهیم‌شاه",u"ابراهیم",u"ابن‌الشیخ",u"ابن",u"ابواسحاق",u"ابوالبشر",u"ابوالجود",u"ابوالحسن",u"ابوالحسین",u"ابوالشمقمق",u"ابوالعباس",u"ابوالعلاء",u"ابوالعلای",u"ابوالفتح‌خان",u"ابوالفتح",u"ابوالفرج",u"ابوالفضل",u"ابوالقاسم",u"ابوالمؤید",u"ابوالنجیب",u"ابوبکر",u"ابوتراب",u"ابوجعفر",u"ابوحامد",u"ابوحفص",u"ابوحنیفه",u"ابوذر",u"ابوزراعه",u"ابوزید",u"ابوسعد",u"ابوسعید",u"ابوسلیمان",u"ابوسلیک",u"ابوسهل",u"ابوشعیب",u"ابوشکور",u"ابوطالب",u"ابوطاهر",u"ابوطیب",u"ابوعبدالله",u"ابوعبید",u"ابوعثمان",u"ابوعلی",u"ابوعمرو",u"ابوغانم",u"ابوماهر",u"ابومحمود",u"ابومسلم",u"ابومعشر",u"ابومنصور",u"ابونصر",u"ابوهلال",u"ابویعقوب",u"ابو",u"ابی‌الخیر",u"ابی",u"اتابک",u"اتان",u"اثیرالدین",u"اثیر",u"احد",u"احسان",u"احسن‌الله",u"احمدبن",u"احمدحسین",u"احمدرضا",u"احمدشاه",u"احمدعلی",u"احمدقلی",u"احمد",u"احولی",u"اخوینی",u"اخی",u"ادریس",u"ادمان",u"ادموند",u"ادوارد",u"ادیب‌الممالک",u"ادیب",u"ادیک",u"اردشیر",u"اردلان",u"اردم‌بر",u"اردوان",u"ارسطو",u"ارسلان",u"ارس",u"ارشاد",u"ارشدالدین",u"ارشد",u"ارشیا",u"اروج",u"اروین",u"ارژنگ",u"ازرقی",u"استاد",u"استوار",u"استپان",u"استیون",u"اسحاق‌خان",u"اسحاق",u"اسدالله",u"اسد",u"اسطرلابی",u"اسفار",u"اسفندیار",u"اسقف",u"اسلام",u"اسماعیل",u"اسمعیل",u"اسپد",u"اسکندر",u"اسیر",u"اشکان",u"اصطخری",u"اصغر",u"اظهر",u"اعتضادالملک",u"افشین",u"افضل‌الدین",u"اف‌ام",u"اقبال",u"البرز",u"البوبصر",u"الشن",u"القاس",u"الله‌وردی",u"الله‌یار",u"المقنع",u"النقوری",u"الهیار",u"اله‌ویردی",u"الکساندر",u"الکس",u"الیاس",u"الیزر",u"امامعلی",u"امامقلی",u"امام‌قلی‌خان",u"امام",u"امانت‌الله",u"امانت‌خان",u"امانوئل",u"امان‌الله",u"امان",u"امجد",u"امرالله",u"امراله",u"امرلال",u"امنون",u"امیدرضا",u"امیدعلی",u"امیدوار",u"امید",u"امیراحسان",u"امیرارسلان",u"امیراصلان",u"امیراعلم",u"امیربهادر",u"امیرحسن",u"امیرحسین",u"امیرحمزه",u"امیرخان",u"امیرخسرو",u"امیررضا",u"امیرشهاب",u"امیرعباس",u"امیرقلی",u"امیرمحمد",u"امیرمختار",u"امیرمسعود",u"امیرمعزز",u"امیرمهدی",u"امیرمهرداد",u"امیرناصر",u"امیرنظام",u"امیرهادی",u"امیرهوشنگ",u"امیرپرویز",u"امیرکبیر",u"امیر",u"امین‌الدین",u"امین‌الشریعه",u"امین‌الله",u"امین‌حسین",u"امین",u"اندی",u"انشاءالله",u"انور",u"انوشیروان",u"اهلی",u"اهوراپیروز",u"اوحدالدین",u"اوحدی",u"اورتاکو",u"اوستاتیوس",u"اوشین",u"اولیاءالله",u"اولیاقلی",u"اوژن",u"اویس",u"اپریم",u"اکبر",u"ایاز",u"ایرج",u"ایزار",u"ایزدی",u"ایلوش",u"ایلیا",u"ایمان",u"ایوان",u"ایوب",u"باباجعفر",u"باباطاهر",u"بابافرج",u"بابا",u"بابوفله",u"بابکن",u"بابک",u"باخرزی",u"باذان",u"باربد",u"بارزان",u"بارویر",u"باغبان",u"باقرخان",u"باقر",u"باقی",u"بالوولو",u"بامداد",u"بامشاد",u"بایرام",u"بایزید",u"بایسنقر",u"بای",u"بختیار",u"بداق",u"بدرالدین",u"بدیع‌الزمان",u"بدیع",u"براتعلی",u"برات",u"برادران",u"برازبد",u"برت",u"برجعلی",u"برخوردار",u"بردیا",u"برزویه",u"برزو",u"برزین",u"برسام",u"برندق",u"برهان‌الدین",u"برگرونی",u"بزرگمهر",u"بزرگ",u"بساطی",u"بسام",u"بستنی",u"بشیر",u"بقلي،",u"بنجامین",u"بنددوز",u"بنیامین",u"بنیک",u"بهاءالدین",u"بهاءالله",u"بهادر",u"بهبد",u"بهتاش",u"بهداد",u"بهراد",u"بهرام",u"بهرنگ",u"بهروز",u"بهزاد",u"بهشاد",u"بهشتی",u"بهلول",u"بهمنیار",u"بهمن",u"بهنام",u"بهنود",u"به‌آفرید",u"بوذرجمهر",u"بولود",u"بونصر",u"بیت‌الله",u"بیجه",u"بیدل",u"بیضای",u"بیطار",u"بیوک",u"بیژن",u"تئوشپا",u"تاج‌الدین",u"ترک‌کشی",u"تریتا",u"تقی‌خان",u"تقی",u"تلیمان",u"تمکین",u"تنها",u"تهماسب",u"تهمورث",u"تهمورس",u"توجی",u"توحید",u"تورج",u"توفیق",u"تونی",u"توکا",u"توکل",u"تیرداد",u"تیلیم",u"تیمور",u"ثقةالاسلام",u"ثمین",u"جابر",u"جاسم",u"جاماسپ",u"جامی",u"جانی",u"جان",u"جاهد",u"جاوید",u"جبار",u"جبرائیل",u"جبریل",u"جرجیس",u"جرج",u"جعفرخان",u"جعفرقلی‌خان",u"جعفرقلی",u"جعفر",u"جغمینی",u"جفاد",u"جلال‌الدین",u"جلال",u"جلدکی",u"جلیل",u"جمالای",u"جمال‌الدین",u"جمال",u"جمشید",u"جنيد",u"جنید",u"جهانبخت",u"جهانبخش",u"جهاندوست",u"جهانشاه",u"جهانشیر",u"جهانگیرخان",u"جهانگیر",u"جواد",u"جوانشیر",u"جوهری",u"جیحون",u"جیسون",u"حاتم",u"حاجی‌خان",u"حاج",u"حاسب",u"حافظ",u"حامد",u"حاکم",u"حبش",u"حبیب‌الله",u"حبیب‌اله",u"حبیب‌بیگ",u"حبیب",u"حبیش",u"حجت‌الله",u"حجت",u"حزین",u"حسام‌الدین",u"حسام‌السلطنه",u"حسام",u"حسان",u"حسنعلی‌بیگ",u"حسنعلی",u"حسن‌آقا",u"حسن‌بیگ",u"حسن‌شاه",u"حسن",u"حسینعلی",u"حسینقلی",u"حسین‌بیگ",u"حسین‌خان",u"حسین‌قلی‌خان",u"حسین",u"حشمت‌الله",u"حشمت",u"حصین",u"حمدالله",u"حمزه",u"حموله",u"حمیدرضا",u"حمید",u"حنظله",u"حنیف",u"حنینا",u"حکاک",u"حکمت‌الله",u"حکیم",u"حیدرخان",u"حیدرعلی‌خان",u"حیدرعلی",u"حیدر",u"خالد",u"خالوحسین",u"خالو",u"خانا",u"خانبابا",u"خانلر",u"خانواده",u"خانچیک",u"خان",u"خاوری",u"خاکشیر",u"خبازی",u"خبیرالملک",u"خداداد",u"خدامراد",u"خدایار",u"خزی",u"خسته",u"خسروخان",u"خسرو",u"خشایار",u"خضر",u"خلیفه",u"خلیل‌الله",u"خلیل",u"خواجه",u"خواجوی",u"خواندمیر",u"خوشدل",u"خیرالله",u"دادشاه",u"داراب",u"دارا",u"داریوش",u"دانشی",u"دانوش",u"دانیال",u"داود",u"داور",u"داوود",u"داوید",u"دخیل‌عباس",u"دخیل",u"درویش‌خان",u"درویش‌رضا",u"درویش",u"دریاقلی",u"دنیل",u"دورمیش‌خان",u"دوستعلی",u"دوست‌محمدخان",u"دوست‌محمد",u"دولت‌محمد",u"دومنیک",u"دکتر",u"دیسم",u"دیوسلطان",u"دیوید",u"ذبیح‌الله",u"ذبیح",u"ذوالفقارخان",u"ذوالفقار",u"رئیس‌علی",u"راجی",u"رافائل",u"رافی",u"راما",u"رامبد",u"رامتین",u"رامسین",u"رامک",u"رامیز",u"رامین",u"رایموند",u"ربیع‌الله",u"ربیع",u"رجب‌علی",u"رجب",u"رحمان",u"رحمت‌الله",u"رحمت",u"رحیم‌بردی",u"رحیم‌علی",u"رحیم",u"رسام",u"رستم‌الحکما",u"رستم‌علی",u"رستم",u"رسول",u"رشیدالدین",u"رشیدخان",u"رشید",u"رضاشاه",u"رضاقلی‌خان",u"رضاقلی‌میرزا",u"رضاقلی",u"رضایا",u"رضا",u"رضی‌الدین",u"رفیع",u"رمضان‌علی",u"رمضان",u"رهام",u"رهی",u"روایات",u"روبرت",u"روبن",u"روبیک",u"روح‌الله",u"روزبه",u"روشن",u"روغنی",u"رونقی",u"رویین",u"روی",u"رکن‌الدوله",u"رکن‌الدین",u"رکن‌الملک",u"ریبین",u"ریویل",u"زادعلی",u"زانیار",u"زاهد",u"زاهر",u"زاون",u"زایر",u"زبیر",u"زرتشت",u"زرونی",u"زرکوب",u"زریر",u"زرین‌دست",u"زعیم‌الدوله",u"زلالی",u"زهیر",u"زوبین",u"زورایر",u"زوریک",u"زکریا",u"زکی‌خان",u"زیدالله",u"زید",u"زینل‌بیگ",u"زین‌الدین",u"زین‌العابدین",u"ساروخان",u"سارو",u"ساسان",u"ساسی",u"ساعد",u"سالارالدوله",u"سالار",u"سالم",u"سامان‌خدا",u"سامان",u"سامر",u"سامسون‌خان",u"ساموئل",u"سامی",u"سام",u"ساناسار",u"سانداک",u"ساندر",u"سبحان",u"سبو",u"سبکتکین",u"ستارخان",u"ستار",u"سجاد",u"سحاب",u"سدیدالدین",u"سدیدالسلطنه",u"سدیک",u"سراج‌الدین",u"سراج",u"سرخوش",u"سردار",u"سرمد",u"سروش",u"سروژ",u"سرژیک",u"سرژ",u"سرکش",u"سرکیس",u"سرگون",u"سعادت",u"سعدالدین",u"سعدالله",u"سعدی",u"سعیدالدین",u"سعیدالعلماء",u"سعیدرضا",u"سعید",u"سفر",u"سلام‌الله",u"سلبعلی",u"سلطان‌علی",u"سلطان",u"سلمان‌خان",u"سلمان",u"سلمویه",u"سلیمان‌خان",u"سلیمان‌میرزا",u"سلیمان",u"سلیم",u"سلی",u"سمایون",u"سمبات",u"سموری",u"سمیر",u"سنباد",u"سنجر",u"سند",u"سنمار",u"سهام‌الدین",u"سهراب",u"سهند",u"سهیل",u"سواره",u"سواک",u"سوران",u"سورنا",u"سورن",u"سوزنی",u"سيد",u"سپنتا",u"سپند",u"سپهر",u"سیامند",u"سیامک",u"سیاه‌خان",u"سیاوش‌بیک",u"سیاوش",u"سیا",u"سیداحسن",u"سیدالعراقین",u"سیدباقر",u"سیدبهلول",u"سیدجلال",u"سیدجواد",u"سیدحسن",u"سیدحسین",u"سیدحمیدرضا",u"سیدرسول",u"سیدسعید",u"سیدشریف",u"سیدشکرخدا",u"سیدعبدالله",u"سیدعبدالکریم",u"سیدعلیرضا",u"سیدعلی‌محمد",u"سیدعلی",u"سیدعیسی",u"سیدغلامرضا",u"سیدمحسن",u"سیدمحمدباقر",u"سیدمحمدحسین",u"سیدمحمدعلی",u"سیدمحمد",u"سیدمحمود",u"سیدمرتضی",u"سیدمصطفی",u"سیدمهدی",u"سیدموسی",u"سیدهادی",u"سیدهاشم",u"سیدکاظم",u"سید",u"سیروان",u"سیروس",u"سیفی",u"سیف‌الدین",u"سیف‌الله",u"سیف",u"سیمون",u"سیناتروک",u"سینا",u"شائول",u"شادمهر",u"شامی",u"شانی",u"شان",u"شاهد",u"شاهرخ‌بیگ",u"شاهرخ‌میرزا",u"شاهرخ",u"شاهمردان",u"شاهو",u"شاهکار",u"شاهین",u"شاه‌اسماعیل",u"شاه‌علی",u"شاه‌محمود",u"شاه‌میرزا",u"شاه",u"شاپور",u"شاپکس",u"شاکر",u"شایان",u"شباب",u"شبیب",u"شجاعت",u"شجاع‌الدین",u"شجاع",u"شرام",u"شرف‌الدوله",u"شرف‌الدین",u"شرف‌خان",u"شروین",u"شریف",u"شعبانعلی",u"شعبان‌خان",u"شعبان",u"شفیع",u"شمد",u"شمسای",u"شمس‌الدوله",u"شمس‌الدین",u"شمس‌العلما",u"شمس‌الله",u"شموئل",u"شمیم",u"شهاب‌الدین",u"شهاب",u"شهباز",u"شهبال",u"شهدی",u"شهراد",u"شهرام",u"شهرداد",u"شهروز",u"شهریار",u"شهنام",u"شهیار",u"شهید",u"شورش",u"شوریده",u"شوقی",u"شکرالله",u"شکرخدا",u"شکور",u"شکیبی",u"شیث",u"شیخعلی‌خان",u"شیخعلی",u"شیخ‌الاسلام",u"شیخ‌الحکماء",u"شیخ‌الرئیس",u"شیخ",u"شیرزاد",u"شیرمحمد",u"شیرکوه",u"شیرکو",u"شین",u"شیون",u"صائب",u"صابر",u"صاحب",u"صادقی‌بیک",u"صادق‌حسین",u"صادق‌خان",u"صادق",u"صاعد",u"صالح‌علی‌شاه",u"صالح",u"صامت",u"صانع",u"صاین",u"صباح",u"صبار",u"صبحی",u"صداقت",u"صدرالاسلام",u"صدرالدین",u"صدرالسادات",u"صدرالممالک",u"صدرا",u"صدیف",u"صدیق",u"صغیر",u"صفار",u"صفای",u"صفدر",u"صفر",u"صفهاني,",u"صفی‌الدین",u"صفی‌علی‌شاه",u"صفی",u"صلاح‌الدین",u"صمد",u"صنیع‌الملک",u"صنیع",u"صهبا",u"صوفی",u"صولت‌الدوله",u"صیدمرادخان",u"ضرغام",u"ضریر",u"ضیاءالدین",u"ضیاءالله",u"ضیاء",u"ضیا",u"طاطاوس",u"طالب",u"طاها",u"طاهر",u"طایر",u"طبیب",u"طرزی",u"طغرل",u"طلحه",u"طهماسب",u"طوفان",u"طیان",u"طیب",u"ظفر",u"ظهیرالدین",u"ظهیری",u"عابدین",u"عابد",u"عادل",u"عارف",u"عاشیق",u"عاصی",u"عبادالله",u"عباد",u"عباسعلی",u"عباسقلی",u"عباس‌آقا",u"عباس",u"عبدالامیر",u"عبدالباقی",u"عبدالبهاء",u"عبدالجبار",u"عبدالجلیل",u"عبدالجواد",u"عبدالحسن",u"عبدالحسین",u"عبدالحمد",u"عبدالحمید",u"عبدالحی",u"عبدالرحمان",u"عبدالرحمن",u"عبدالرحیم",u"عبدالرزاق",u"عبدالرسول",u"عبدالرشید",u"عبدالرضا",u"عبدالرفیع",u"عبدالصمد",u"عبدالعزیز",u"عبدالعظیم",u"عبدالعلی",u"عبدالغافر",u"عبدالغفار",u"عبدالغفور",u"عبدالفتاح",u"عبدالقادر",u"عبدالقاهر",u"عبدالقدیر",u"عبداللطیف",u"عبدالله",u"عبدالمالک",u"عبدالمجید",u"عبدالمحمد",u"عبدالملک",u"عبدالناصر",u"عبدالنبی",u"عبدالنقی",u"عبدالنور",u"عبدالهادی",u"عبداله",u"عبدالواحد",u"عبدالوحید",u"عبدالوهاب",u"عبدالکریم",u"عبدی",u"عبد",u"عبرت",u"عثمان",u"عدنان",u"عربعلی",u"عرش",u"عرفان",u"عرفی",u"عزالدوله",u"عزالدین",u"عزت‌الله",u"عزیزالله",u"عزیزخان",u"عزیزویسی",u"عزیز",u"عسجدی",u"عسکر",u"عصار",u"عضت‌الله",u"عضدالدوله",u"عضدالدین",u"عضدالملک",u"عطاءالله",u"عطاء",u"عطاالله",u"عطار",u"عطاملک",u"عطا",u"عظیم",u"عقیل",u"علاءالدوله",u"علاءالدین",u"علاءالسلطنه",u"علامه",u"علا",u"علوان",u"علیداد",u"علیرضا",u"علیقلی",u"علیمرادخان",u"علی‌اشرف",u"علی‌اصغر",u"علی‌اکبر",u"علی‌بابا",u"علی‌بیگ",u"علی‌حسین",u"علی‌خان",u"علی‌رام",u"علی‌سمیل",u"علی‌محمد",u"علی‌مراد",u"علی‌مرتضی",u"علی‌میرزا",u"علی‌نعمت",u"علی‌نقی",u"علی‌همت",u"علی‌پناه",u"علی",u"عمادالاسلام",u"عمادالدوله",u"عمادالدین",u"عمادالکتاب",u"عماد",u"عماره",u"عمار",u"عمان",u"عمران",u"عمعق",u"عموحاجی",u"عمو",u"عنایت‌الله",u"عنایت",u"عنصرالمعالی",u"عنصری",u"عنقای",u"عوبدیا",u"عوض",u"عیسی",u"عیشی",u"عین‌الدوله",u"عین‌القضات",u"عین‌الله",u"غازی‌بیگ",u"غازی",u"غانم",u"غبار",u"غزالی",u"غضائری",u"غضنفر",u"غفار",u"غفور",u"غلامحسن",u"غلامحسین‌خان",u"غلامحسین",u"غلامرضاخان",u"غلامرضا",u"غلامعلی",u"غلام‌عباس",u"غلام‌محمد",u"غلام",u"غمام",u"غنی",u"غورک",u"غیاث‌الدین",u"غیب‌الله",u"غیرت",u"فؤاد",u"فاتح",u"فاتک",u"فاروق",u"فاضل‌خان",u"فاضل",u"فایز",u"فایض",u"فتال",u"فتحعلی‌شاه",u"فتحعلی",u"فتح‌الله",u"فتح",u"فتوحی",u"فخرالدین",u"فداحسین",u"فرامرز",u"فرامند",u"فربد",u"فرج‌الله",u"فرج",u"فرح‌بخش",u"فرخزاد",u"فرخ",u"فرداد",u"فردریش",u"فردوس",u"فردین",u"فرزاد",u"فرزان",u"فرزین",u"فرشاد",u"فرمان",u"فرنوش",u"فرهاد",u"فرهنگ",u"فرود",u"فرورتیش",u"فروغی",u"فریاد",u"فریبرز",u"فریدالدین",u"فریدون",u"فرید",u"فصیح",u"فضائل",u"فضل‌الله",u"فضل",u"فغفور",u"فقیر",u"فلکی",u"فلیکس",u"فیروزآبادی",u"فیروزشاه",u"فیروز",u"فیضی",u"فیض‌الله",u"فیض‌اله",u"فیض",u"فیله",u"قاآنی",u"قائم‌مقام",u"قابوس",u"قادر",u"قازار",u"قاسمعلی",u"قاسم‌آقای",u"قاسم‌خان",u"قاسم",u"قاضی",u"قاله‌مه‌ره",u"قانع",u"قباد",u"قبولی",u"قدرت‌الله",u"قدرت",u"قدسی",u"قدمعلی",u"قدیر",u"قربان‌علی",u"قربان",u"قزل",u"قصاب",u"قطان",u"قطب‌الدین",u"قطران",u"قمری",u"قهرمان‌خان",u"قهرمان",u"قوام‌الدین",u"قورخمس‌خان",u"قوسی",u"قیصر",u"لئوناردو",u"لئون",u"لارنس",u"لاری",u"لامعی",u"لبیبی",u"لسانی",u"لشکرورز",u"لطفعلی‌خان",u"لطفی",u"لطف‌الله",u"لطف‌علی",u"لطف",u"لطیف",u"لفته",u"لقمان",u"لهراسپ",u"لوریس",u"لون",u"لوکری",u"لوگا",u"لیث",u"لیلاج",u"مأذون",u"مؤیدالممالک",u"مؤید",u"مئیر",u"ماجد",u"مارتیروس",u"مارتیک",u"ماردوک",u"مارکار",u"مارکو",u"مازیار",u"ماسیس",u"ماشاءالله",u"ماشاالله",u"ماطه‌وس",u"مالک",u"مانوک",u"مانی",u"ماهان",u"مبارک‌شاه",u"مبین",u"متین",u"مجاهد",u"مجتبا",u"مجتبی",u"مجدالاسلام",u"مجدالدین",u"مجدالملک",u"مجد",u"مجذوب",u"مجرم",u"مجنون",u"مجیدرضا",u"مجید",u"مجیرالدین",u"محب‌علی",u"محتشم",u"محدث",u"محراب",u"محرم",u"محسن",u"محقق",u"محمدابراهیم",u"محمداحمد",u"محمداسماعیل",u"محمدامین",u"محمداکرم",u"محمدباقر",u"محمدتقی",u"محمدجعفر",u"محمدجلال",u"محمدجلیل",u"محمدجواد",u"محمدحسن‌خان",u"محمدحسن",u"محمدحسین",u"محمدخان",u"محمدرئوف",u"محمدرحیم",u"محمدرشید",u"محمدرضا",u"محمدرفیع",u"محمدزمان",u"محمدسعید",u"محمدسلیمان",u"محمدشاه",u"محمدشریف",u"محمدشفیع",u"محمدشهاب",u"محمدصادق",u"محمدصالح",u"محمدطاهر",u"محمدظاهر",u"محمدعلی‌شاه",u"محمدعلی",u"محمدفؤاد",u"محمدقاسم",u"محمدقسیم",u"محمدقلی",u"محمدقیوم",u"محمدمحسن",u"محمدمنصور",u"محمدمهدی",u"محمدمیرک",u"محمدناصر",u"محمدنبی",u"محمدنقی",u"محمدهادی",u"محمدهاشم",u"محمدوحید",u"محمدولی",u"محمدکاظم",u"محمدکریم",u"محمدیوسف",u"محمد",u"محمودبن",u"محمودرضا",u"محمودعلی",u"محمود",u"محوی",u"محیا",u"محیط",u"محی‌الدین",u"مختار",u"مخلص",u"مخیتار",u"مدام",u"مدیا",u"مرادعلی",u"مرادمیرزا",u"مراد",u"مرتضی‌قلی",u"مرتضی",u"مرداویج",u"مردخای",u"مرد",u"مرشد",u"مرنا",u"مرگ",u"مزار",u"مزدک",u"مسرجویه",u"مسعود",u"مسلم",u"مسیب‌خان",u"مسیحی",u"مسیر",u"مشتاق",u"مشتی",u"مشدی",u"مشفق",u"مشیت",u"مشیر",u"مصطفی‌خان",u"مصطفی‌قلی",u"مصطفی",u"مصلح‌الدین",u"مصلح",u"مظاهر",u"مظفرالدین‌شاه",u"مظفر",u"مظهر",u"معتمد",u"معجز",u"معراج",u"معرفت‌علی",u"معروف",u"معزالدوله",u"معزدیوان",u"معطرعلیشاه",u"معین‌الدین",u"معین",u"مغربی",u"مفتون",u"مفضل",u"مفید",u"مقبل",u"مقداد",u"مقدس",u"مقصود",u"ملااحمد",u"ملاحسین",u"ملاصدرا",u"ملاعلی",u"ملامحمد",u"ملامراد",u"ملا",u"ملک‌الشعرای",u"ملک‌محمد",u"ملک",u"ملیجک",u"ممتاز",u"مناهیم",u"منجیک",u"منشه",u"منصور",u"منعم‌الدین",u"منورعلی‌شاه",u"منوچهر",u"منیرالدین",u"مهبد",u"مهداد",u"مهدیار",u"مهدی‌خان",u"مهدی‌قلی",u"مهدی",u"مهراب",u"مهراد",u"مهران",u"مهرداد",u"مهرزاد",u"مهرشاد",u"مهرعلی",u"مهیار",u"مه‌آفرید",u"موبد",u"موتا",u"موریس",u"موسی‌الرضا",u"موسی",u"موشق",u"موعود",u"مولانا",u"مولوی",u"موژان",u"مکتبی",u"مگردیچ",u"میثاق",u"میثم",u"میرابراهیم",u"میرابوالفضل",u"میرجلال",u"میرحسن",u"میرحسین",u"میرخواند",u"میرداماد",u"میرزاحسن",u"میرزاده",u"میرزا",u"میرشاد",u"میرصالح",u"میرصلاح",u"میرطاهر",u"میرعلام",u"میرعلی",u"میرعماد",u"میرفتاح",u"میرقسمت",u"میرمحمدحسین",u"میرمحمد",u"میرمصور",u"میرمعزالدین",u"میرهادی",u"میرهاشم",u"میرهانی",u"میرک",u"میر",u"میشل",u"میلاد",u"میکائیل",u"ناتاشا",u"ناخدا",u"نادرشاه",u"نادر",u"نادعلی",u"ناری",u"ناصرالحق",u"ناصرالدین",u"ناصر",u"ناظم‌الاطبا",u"ناظم",u"نامی",u"ناپلئون",u"نایب",u"نبیل",u"نبی‌الله",u"نبی",u"نثاری",u"نجات‌الله",u"نجفقلی",u"نجف",u"نجم‌الدین",u"نجم",u"نجیب‌الدین",u"نجیب",u"نرشخی",u"نریمان‌خان",u"نریمان",u"نسوی",u"نشاط",u"نشیط",u"نصرالله",u"نصرت‌الله",u"نصر",u"نصور",u"نصیب",u"نصیر",u"نظام‌الدین",u"نظام‌العلما",u"نظام",u"نظرعلی",u"نظرمحمد",u"نظر",u"نعمت‌الله",u"نعمت",u"نعیم",u"نقاش",u"نواب",u"نوح",u"نوذر",u"نورالدین",u"نورالله",u"نورعلیشاه",u"نورعلی",u"نورمحمد",u"نوریک",u"نور",u"نوشاد",u"نوشزاد",u"نوشیروان",u"نوعی",u"نوید",u"نکتار",u"نیما",u"نیکزاد",u"نیکولا",u"نیکول",u"نیک‌آهنگ",u"هاتف",u"هادی‌خان",u"هادی",u"هاراطون",u"هارطیون",u"هارون",u"هاشم",u"هانس",u"هانیبال",u"هاوارد",u"هاکوپ",u"هایک",u"هبه‌الله",u"هجویری",u"هدایت‌الله",u"هدایت",u"هراند",u"هربرت",u"هرمز",u"هفت‌کچلون",u"هلالی",u"همام",u"همایون",u"همت‌الله",u"همت",u"هنریک",u"هنری",u"هوتن",u"هوشمند",u"هوشنگ",u"هوشیار",u"هومان",u"هومن",u"هوهانس",u"هووخشتره",u"هژبر",u"هژیر",u"هیبت‌الله",u"هیمن",u"هیچ",u"واحد",u"وارتان",u"واردگس",u"وارطان",u"واروژ",u"وازگن",u"وازیک",u"واسیلیس",u"واسیلی",u"واصل",u"واله",u"والودیا",u"واهان",u"واهاک",u"واهرام",u"واهه",u"واهیک",u"وای",u"وجه‌الله",u"وجیه‌الله",u"وحشی",u"وحید",u"ودود",u"وردان",u"ورقه",u"وریا",u"وصاف",u"وصال",u"وفاعلی‌شاه",u"وفایی",u"وفا",u"وقار",u"ولوالجی",u"ولید",u"ولی‌الله",u"ولی‌خلیفه",u"ولی",u"وکیل",u"ویلیام",u"ویکتور",u"ویگن",u"پاتریک",u"پارسا",u"پایان",u"پدرام",u"پدریس",u"پرنس",u"پرهام",u"پرواز",u"پرویز",u"پشنگ",u"پطرس",u"پطروس",u"پندار",u"پهلوان",u"پوربهای",u"پوريا",u"پولاد",u"پولس",u"پویان",u"پویا",u"پژمان",u"پیام",u"پیتر",u"پیرعلی",u"پیرمحمد",u"پیروز",u"پیریحیی",u"پیریونس",u"پیر",u"پیغمبر",u"پیمان",u"چایم",u"چراغ‌علی",u"چنگیز",u"چهره‌نگار",u"ژازه",u"ژاک",u"ژرژ",u"ژورس",u"ژوزف",u"ژیان",u"کارن",u"کارو",u"کارکیا",u"کاسپین",u"کاظم",u"کافرک",u"کافی",u"کامبوزیا",u"کامبیز",u"کامران",u"کامل",u"کامیار",u"کامی",u"کاوه",u"کاووس",u"کرامت‌الله",u"کرامت",u"کربلایی",u"کرم",u"کریستاپور",u"کریستف",u"کریم‌خان",u"کریم",u"کسایی",u"کسرا",u"کسری",u"کلنل",u"کلیم",u"کمال‌الدین",u"کمال‌الملک",u"کمال",u"کمیل",u"کنت",u"کنعان",u"کوثر",u"کورس",u"کورش",u"کوروس",u"کوروش",u"کوشیار",u"کوهیار",u"کوپال",u"کوچر",u"کیانوش",u"کیان",u"کیاوش",u"کیا",u"کیخسرو",u"کینگ",u"کیهان",u"کیوان",u"کیوس",u"کیومرث",u"کیکاووس",u"گئورک",u"گارنیک",u"گرجی",u"گردیزی",u"گرشا",u"گرنیک",u"گروس",u"گرگین‌خان",u"گریگور",u"گلبن",u"گلچین",u"گل‌محمد",u"گنجعلیخان",u"گنجعلی",u"گندفر",u"گنزابرا",u"گودرز",u"گورگن",u"گوین",u"یاثر",u"یارمحمدخان",u"یاری",u"یاسر",u"یاس",u"یاشا",u"یحیی",u"یدالله",u"یدیدیا",u"یرواند",u"یزدان‌خواست",u"یزدان",u"یزدین",u"یعسوب‌الدین",u"یعقوبعلی",u"یعقوب",u"یوسفعلی",u"یوسف‌خان",u"یوسف",u"یوناتن",u"یونس",u"یپرم‌خان"]
Femail_names=[u"آبنوس",u"آترین",u"آتنا",u"آتنه",u"آتوسا",u"آذرمیدخت",u"آذرنوش",u"آذر",u"آذین",u"آرام",u"آرتادخت",u"آرزو",u"آرمیتا",u"آرینیس",u"آزاده",u"آزرمی‌دخت",u"آزیتا",u"آزین",u"آسیه",u"آشا",u"آفت",u"آفرین",u"آلینوش",u"آمنه",u"آناهیتا",u"آنا",u"آنیک",u"آهو",u"آوا",u"آوید",u"آیدا",u"آیسان",u"آیسا",u"آیلین",u"آیناز",u"احترام",u"اخترالدوله",u"اخترالسادات",u"اختر",u"ارغوان",u"ارفع",u"اشرف‌الملوک",u"اشرف",u"اعظم‌السادات",u"اعظم",u"افتخارالسلطنه",u"افسانه",u"افسرالسادات",u"افسر",u"افسون",u"افلیا",u"اقدس",u"الاهه",u"السا",u"الناز",u"الهام‌السادات",u"الهام",u"الهه",u"الیزابت",u"الیکا",u"امّ",u"امیتیس",u"امیربانو",u"امیلیا",u"امینه",u"ام",u"اندیشه",u"انسیه",u"انوشه",u"اکرم",u"ایدن",u"ایراندخت",u"ایرن",u"باران",u"بانو",u"بتول",u"بتی",u"بدرالزمان",u"بدرالسادات",u"بدرالملوک",u"بدری",u"برسابه",u"بلقیس",u"بنفشه",u"بهاران",u"بهاره",u"بهارک",u"بهار",u"بهجت‌العلما",u"بهجت",u"بهدخت",u"بهروزه",u"بهناز",u"بهنوش",u"بهیه",u"بیتا",u"بی‌بی‌خانم",u"بی‌بی",u"تاجلی",u"تاج‌الدوله",u"تاج‌السلطنه",u"تاج‌الملوک",u"تاج‌ماه",u"تارا",u"تانیا",u"تبسم",u"ترانه",u"ترزیا",u"ترلان",u"ترکان",u"تندیس",u"تهمینه",u"توبا",u"توتیا",u"توران",u"تینا",u"ثریا",u"جمیله",u"جهان‌ملک",u"جوانه",u"جیران",u"حاجیه",u"حانیه",u"حدیثه",u"حدیث",u"حریر",u"حسناء",u"حلیمه",u"حمیده",u"حمیرا",u"حنانه",u"حنا",u"حوریه",u"حیران",u"خاتون",u"خازن‌الدوله",u"خاطره",u"خجسته",u"خدیجه",u"خیرالنساء",u"دارای‌دخت",u"دریا",u"دلارام",u"دلارا",u"دلبر",u"دلکش",u"دلیله",u"دنیا",u"دوروتی",u"دیبا",u"رؤیا",u"رابعه",u"راتبه",u"راحله",u"راشین",u"راضیه",u"رامش",u"رامونا",u"رامینا",u"ربابه",u"رباب",u"رخسانه",u"رخشان",u"رزا",u"رزیتا",u"رز",u"رشحه",u"رضوان",u"رعنا",u"رفعت",u"رقیه",u"رها",u"روجا",u"روح‌انگیز",u"روح‌پرور",u"رودابه",u"روزت",u"روزگون",u"روشنک",u"روفیا",u"رومینا",u"روناک",u"روژان",u"روژینا",u"روژین",u"رویا",u"ریحانه",u"ریما",u"زبیده",u"زروان‌دخت",u"زرین",u"زری",u"زندخت",u"زهرا",u"زهره",u"زویا",u"زیبا",u"زینب",u"زینت‌السادات",u"زینت",u"زیگرید",u"ساتو",u"ساحره",u"سارا",u"ساره",u"سارینا",u"ساغر",u"ساقی",u"سالومه",u"سامیه",u"ساناز",u"سانیا",u"سایه",u"سبا",u"ستاره",u"سحر",u"سرور",u"سعیده",u"سلیمه",u"سمانه",u"سمیرا",u"سمیه",u"سهیلا",u"سودابه",u"سوره",u"سوری",u"سوزان",u"سوسن",u"سوفی",u"سولماز",u"سونیا",u"سونیتا",u"سوگل",u"سوگند",u"سپتا",u"سپیده",u"سکینه",u"سیده",u"سیما",u"سیمین",u"سیندخت",u"شادی",u"شاپی",u"شایسته",u"شبنم",u"شراره",u"شعله",u"شقایق",u"شمسی",u"شمس‌الملوک",u"شهربانو",u"شهرزاد",u"شهرناز",u"شهرنوش",u"شهره",u"شهلا",u"شهناز",u"شهپر",u"شهیندخت",u"شهین",u"شورانگیز",u"شوشاندخت",u"شوکا",u"شوکت",u"شکرانه",u"شکوفه",u"شکوه",u"شکیلا",u"شیدا",u"شیده",u"شیرازه",u"شیرین",u"شیفته",u"شیلا",u"شیما",u"شیوا",u"صاحبه",u"صبا",u"صدرالملوک",u"صدف",u"صدیقه",u"صغرا",u"صغری",u"صفیه",u"صوفیا",u"ضیاءالسلطنه",u"طاهره",u"طلا",u"طلعت",u"طناز",u"طوسی",u"طوطی",u"طیبه",u"عاتقه",u"عاطفه",u"عالیه",u"عایشه",u"عذرا",u"عزیزه",u"عزیه",u"عسل",u"عشا",u"عشرت",u"عصمت‌الدوله",u"عصمت",u"عفت",u"عفیفه",u"عهدیه",u"غزاله",u"غزال",u"غزل",u"غنچه",u"غوغا",u"فائزه",u"فاخره",u"فاطمه",u"فاطیما",u"فتانه",u"فخرآفاق",u"فخرالدوله",u"فخرالزمان",u"فخرالسادات",u"فخرعظمی",u"فخری",u"فراتاگون",u"فرانک",u"فرحناز",u"فرح",u"فرخنده",u"فرخ‌رو",u"فرخ‌لقا",u"فرزانه",u"فرشته",u"فرناز",u"فرنگیس",u"فروزان",u"فروزنده",u"فروز",u"فروغ‌الدوله",u"فروغ‌الملک",u"فروغ",u"فریال",u"فریبا",u"فریده",u"فریماه",u"فریناز",u"فقیهه",u"فلامک",u"فلورا",u"فلور",u"فهیمه",u"فیروزه",u"قرةالعین",u"قشنگ",u"قمرالملوک",u"قمر",u"لادن",u"لاله",u"لرتا",u"لعبت",u"لعیا",u"لوریک",u"لونا",u"لیدا",u"لیلا",u"لیلیت",u"لیلی",u"لیندا",u"مائده",u"مادام",u"مارال",u"مارشا",u"ماریا",u"مارینا",u"ماری",u"ماماعصمت",u"مامک",u"مانا",u"ماندانا",u"ماندا",u"مانیا",u"مانیکا",u"ماهایا",u"ماهدخت",u"ماهرخ",u"ماه‌سلطان",u"ماه‌چهره",u"ماه‌گل",u"مبینا",u"محبوبه",u"محبویه",u"محترم",u"محدثه",u"مرجانه",u"مرجان",u"مرضیه",u"مرمر",u"مروارید",u"مروا",u"مریلا",u"مریم",u"مری",u"مستانه",u"مستوره",u"مطهره",u"معصومه",u"ملودی",u"ملوسک",u"ملوک",u"ملکه",u"ملک‌جان",u"ملیجه",u"ملیحه",u"ملیسا",u"ملینا",u"ملیکا",u"منجمه",u"منصوره",u"منیره",u"منیرو",u"منیر",u"منیژه",u"مهتاب",u"مهتاج",u"مهتا",u"مهدخت",u"مهدیس",u"مهدیه",u"مهرانه",u"مهرانگیز",u"مهراوه",u"مهربانو",u"مهرتاج",u"مهرخ",u"مهرناز",u"مهرنوش",u"مهروز",u"مهری",u"مهسا",u"مهستی",u"مهشاد",u"مهشید",u"مهناز",u"مهنوش",u"مهوش",u"مهگل",u"مهین",u"مه‌لقا",u"مورین",u"مولود",u"مونا",u"مژان",u"مژده",u"مژگان",u"مکرمه",u"میترا",u"میشا",u"میمنت",u"مینا",u"مینو",u"میهن",u"نادره",u"نادیا",u"نارملا",u"نازآفرین",u"نازنین",u"نازگل",u"نازیلا",u"نازی",u"ناهید",u"نجمه",u"نجمی",u"نجم‌السلطنه",u"نخشاب",u"ندا",u"نرجس",u"نرگس",u"نزهت",u"نسترن",u"نسرین",u"نسیم",u"نصرت",u"نعیمه",u"نغمه",u"نفیسه",u"نلی",u"نهال",u"نورالهدی",u"نورا",u"نورین",u"نوری",u"نوشابه",u"نوشین",u"نوش‌آفرین",u"نکیسا",u"نگارالسلطنه",u"نگار",u"نگین",u"نیره",u"نیلوفر",u"نیمتاج",u"نینا",u"نیوشا",u"نیکتاج",u"نیکو",u"نیکی",u"نیک‌آوا",u"هاجر",u"هاله",u"هانا",u"هانیه",u"هایده",u"هدیه",u"هستی",u"هلن",u"هلیا",u"هما",u"همدم‌السلطنه",u"هنگامه",u"هیلا",u"والنتین",u"وانشا",u"وحیده",u"ویدا",u"ویشکا",u"ویکتوریا",u"پارمیدا",u"پارمین",u"پانته‌آ",u"پانیذ",u"پانی",u"پاکسیما",u"پدیده",u"پرتو",u"پرخیده",u"پردیس",u"پرستو",u"پرند",u"پرنیان",u"پروانه",u"پروین‌دخت",u"پروین",u"پریا",u"پریخان",u"پریدخت",u"پریرخ",u"پریزاد",u"پریسا",u"پریناز",u"پرینوش",u"پریوش",u"پری‌چهر",u"پری‌یوش",u"پری",u"پوراندخت",u"پوران",u"پوری",u"پونه",u"پوپک",u"پگاه",u"چکامه",u"چیستا",u"ژاله",u"ژانت",u"ژاکلین",u"ژیلا",u"ژینا",u"ژینوس",u"کاترین",u"کارمل",u"کارینا",u"کاملیا",u"کبرا",u"کبری",u"کتایون",u"کریستین",u"کلارا",u"کمند",u"کوکب",u"کیانا",u"کیمیا",u"گراناز",u"گلاب",u"گلاره",u"گلاله",u"گلبانو",u"گلبرگ",u"گلبهار",u"گلرخ",u"گلسا",u"گلشاد",u"گلشن",u"گلشید",u"گلشیفته",u"گلفام",u"گلمیس",u"گلنار",u"گلناز",u"گلنسا",u"گلنوش",u"گلوریا",u"گلپری",u"گلچهره",u"گلی",u"گوهرالشریعه",u"گوهرشاد",u"گوهر",u"گوگوش",u"گیتا",u"گیتی",u"گیزلا",u"گیسو",u"یاسمن",u"یاسمینا",u"یاسمین",u"یسنا",u"یوتاب",u"یکتا",u"یگانه"]
persian_month={u'فروردین':1,u'اردیبهشت':2,
               u'خرداد':3,u'تیر':4,
               u'مرداد':5,u'شهریور':6,
               u'مهر':7,u'آبان':8,
               u'آذر':9,u'دی':10,
               u'بهمن':11,u'اسفند':12
              }
Gerygorian_month={u'ژانویه':1,u'فوریه':2,
               u'مارس':3,'مارچ':3,u'مه':4,
               u'می':4,u'آوریل':5,'آپریل':5,
               u'ژوئن':6,u'جون':6,u'ژوئیه':7,
               u'جولای':7,u'اوت':8,u'آگست':8,u'آگوست':8,
               u'سپتامبر':9,u'اکتبر':10,u'نوامبر':11,u'دسامبر':12
              }

faSite=pywikibot.Site('fa',fam='wikipedia')
trans_occ={u'نویسنده':u'نویسندگان',
           u'پدیدآور':u'نویسندگان',
           u'دیپلمات':u'دیپلمات‌های',
           u'مدیر عامل اجرایی':u'مدیر عاملان اجرایی'
           }
switch_occ={u'مجتهد':u'روحانی',           u'روحانیان':u'روحانی',           u'امام جمعه':u'روحانی', u'ترجمه':u'مترجم',u'روزنامه نگار':u'روزنامه‌نگار',u'روزنامه‌نگاری':u'روزنامه‌نگار',
           u'امام جمعه موقت':u'روحانی',           u'اجتهاد':u'روحانی',           u'مرجع تقلید':u'روحانی',           u'مجتهد اعلم':u'روحانی',u'وبلاگ':u'وبلاگ‌نویس',
           u'آیت‌الله':u'روحانی',           u'حجت‌السلام':u'روحانی',           u'حجه‌اسلام':u'روحانی',           u'حجه اسلام':u'روحانی',u'وب نوشت':u'وبلاگ‌نویس',u'وب‌نوشت':u'وبلاگ‌نویس',
           u'حجة‌اسلام':u'روحانی',           u'حجة اسلام':u'روحانی',           u'مفتی':u'روحانی',           u'پاپ':u'روحانی',           u'اسقف':u'روحانی',
           u'کاردینال':u'روحانی',           u'کشیش':u'روحانی',           u'خاخام':u'روحانی',         u'اسقف اعظم':u'روحانی',        u'آیت‌الله عظمی':u'روحانی',
           u'فقیه':u'روحانی',           u'چامه‌سرا':u'شاعر',           u'چامه سرا':u'شاعر',           u'غزل سرا':u'شاعر',           u'غزل‌سرا':u'شاعر',
           u'سخنسرا':u'شاعر',           u'سخن‌سرا':u'شاعر',           u'سخن سرا':u'شاعر', u'فیلمبرداری':u'فیلم‌بردار',u'فیلمبردار':u'فیلم‌بردار',
           u'ریاضیات':u'ریاضی‌دان',           u'فیزیک':u'فیزیک‌دان',           u'شیمی':u'شیمی‌دان',u'نجوم':u'ستاره‌شناس', u'منجم':u'ستاره‌شناس',u'صداپیشه':u'صدا پیشه',
           u'ادبیات':u'ادیب',       u'خوشنویس':u'خوشنویس',  u'خوشنویسان':u'خوشنویس',  u'خطاط':u'خوشنویس', u'داستان':u'داستان‌نویس', u'شعر':u'شاعر',
           u'چامه':u'شاعر',         u'پزشکی':u'پزشک',        u'معماری':u'معمار',    u'موسیقی':u'موسیقی‌دان', u'موسیقیدان':u'موسیقی‌دان', u'مطرب':u'موسیقی‌دان',
           }
no_link_item={u"آتشفشان‌شناس":u"Q7940086",u"آدم‌کشی زنجیره‌ای":u"Q484188",u"قاتل زنجیره‌ای":u"Q484188",u"آرایشگر":u"Q55187",u"سلمانی":u"Q55187",
            u"آشپز":u"Q3499072",u"آماردان":u"Q2732142",u"آموزگار":u"Q37226",u"آهنگساز":u"Q36834",u"اتومبیل‌ران فرمول ۱":u"Q10841764",
            u"ادیب":u"Q18195617",u"ارزیاب":u"Q335757",u"استاد دانشگاه":u"Q1622272",u"استاد":u"Q121594",u"اسقف اعظم":u"Q964186",u"اسقف":u"Q4917468",
            u"اسپرانتیست":u"Q860918",u"اسکیت‌باز سرعت":u"Q10866633",u"اسکیت‌باز نمایشی":u"Q13219587",u"اسکی‌باز آلپاین":u"Q4144610",u"اسکی‌باز صحرانوردی":u"Q13382608",
            u"اسکی‌باز پرش":u"Q13382603",u"اسکی‌باز":u"Q4270517",u"افشاگر تقلب":u"Q26102",u"اقتصاددان":u"Q188094",u"اقیانوس‌شناس":u"Q3546255",u"امپراتور":u"Q39018",
            u"انسان‌شناس":u"Q4773904",u"بازرگان":u"Q43845",u"تاجر":u"Q43845",u"بازیکن بسکتبال":u"Q3665646",u"بسکتبالیست":u"Q3665646",u"بازیکن بیسبال":u"Q10871364",
            u"بیسبالیست":u"Q10871364",u"بازیکن تنیس روی میز":u"Q13382519",u"بازیکن راگبی":u"Q13415036",u"بازیکن فوتبال":u"Q937857",u"فوتبالیست":u"Q937857",
            u"بازیکن هاکی روی یخ":u"Q11774891",u"بازیکن هندبال":u"Q13365117",u"بازیکن والیبال ساحلی":u"Q17361156",u"بازیکن والیبال":u"Q15117302",u"والیبالیست":u"Q15117302",
            u"بازیکن پوکر":u"Q15295720",u"پوکرباز":u"Q15295720",u"بازیکن پینگ‌پنگ":u"Q13382519",u"پینگ‌پونگ‌باز":u"Q13382519",u"بازیکن کریکت":u"Q12299841",
            u"بازیگر خردسال":u"Q970153",u"بازیگر سینما":u"Q10800557",u"بازیگر فیلم پورنوگرافی":u"Q488111",u"پورن‌استار":u"Q488111",u"باستان‌شناس":u"Q3621491",
            u"باغبان":u"Q3140857",u"بالرین":u"Q805221",u"بایگان":u"Q635734",u"بدل‌کار":u"Q465501",u"بدمینتون‌باز":u"Q13141064",u"بازیکن بدمینتون":u"Q13141064",
            u"برق‌کار":u"Q165029",u"برنامه‌نویس":u"Q5482740",u"بوم‌شناس":u"Q15839134",u"بوکسور":u"Q11338576",u"مشت‌زن":u"Q11338576",u"بیوفیزیکدان":u"Q14906342",
            u"تدوین‌گر":u"Q7042855",u"ترانه‌سرا":u"Q753110",u"تصویرگر":u"Q644687",u"تنیس‌باز":u"Q10833314",u"تهیه‌کننده بازی ویدئویی":u"Q2702296",
            u"تهیه‌کننده تلویزیونی":u"Q578109",u"تهیه‌کننده موسیقی":u"Q183945",u"تهیه‌کننده":u"Q3282637",u"توسعه‌دهنده بازی‌های رایانه‌ای":u"Q210167",
            u"توسعه‌دهنده وب":u"Q6859454",u"توسعه‌دهنده":u"Q183888",u"تولیدکننده":u"Q3922505",u"تکواندوکار":u"Q13382533",u"تیرانداز":u"Q17486376",
            u"جامعه‌شناس":u"Q2306091",u"جانورشناس":u"Q350979",u"جراح":u"Q774306",u"جغرافی‌دان":u"Q901402",u"جغرافیدان":u"Q901402",u"جلاد":u"Q207651",
            u"جمع‌کننده":u"Q3243461",u"جودوکار":u"Q6665249",u"خادم":u"Q4504549",u"خبرنگار":u"Q1155838",u"خلبان تک‌خال":u"Q222982",u"خلبان جنگنده":u"Q618694",
            u"خلبان":u"Q2095549",u"خواننده اپرا":u"Q2865819",u"خواننده":u"Q177220",u"خواننده-ترانه‌پرداز":u"Q488205",u"خوشنویس":u"Q3303330",u"خیاط زنانه":u"Q4845479",
            u"نیکوکار":u"Q13472585",u"دادرس":u"Q4594605",u"دادستان":u"Q600751",u"داروساز":u"Q105186",u"داروشناس":u"Q2114605",u"دامپزشکی":u"Q202883",u"دانشمند زراعت":u"Q1781198",
            u"دانشمند علوم اجتماعی":u"Q15319501",u"دانشمند محاسباتی":u"Q5157338",u"دانشمند نجوم":u"Q16742203",u"دانشمند همه چیز دان":u"Q270141",u"علامه":u"Q270141",
            u"دانشمند هوا و فضا":u"Q15143181",u"دانشمند":u"Q901",u"داور فوتبال":u"Q859528",u"دبیرکل سازمان ملل متحد":u"Q81066",
            u"دلال":u"Q1424605",u"دندان‌پزشک":u"Q27349",u"دولت‌مرد":u"Q372436",u"دونده دو استقامت":u"Q4439155",u"دونده دو با مانع":u"Q13724897",
            u"دونده دو نیمه‌استقامت":u"Q13381753",u"دونده ماراتن":u"Q13382460",u"دوچرخه‌سوار پیست":u"Q15117395",u"دوچرخه‌سوار":u"Q2309784",
            u"دیرین‌شناس":u"Q1662561",u"دیپلمات":u"Q193391",u"دی‌جی":u"Q130857",u"رئیس دانشگاه":u"Q212071",u"راننده خودروی مسابقه‌ای":u"Q15958185",
            u"راننده رالی":u"Q10842936",u"راننده مسابقه‌ای":u"Q378622",u"راهبه":u"Q191808",u"راهب":u"Q733786",u"راهنمای کوه":u"Q819677",u"رخنه‌گر":u"Q1487",
            u"هکر":u"Q1487",u"رستوران‌دار":u"Q3427922",u"رقاص لختی":u"Q1141526",u"رقصنده":u"Q5716684",u"رقاص":u"Q5716684",u"رمان‌نویس":u"Q6625963",
            u"رمان نویس":u"Q6625963",u"رهبر ارکستر":u"Q158852",u"رهبر مذهبی":u"Q15995642",u"روانپزشک":u"Q211346",u"روان‌پزشک":u"Q211346",u"روان‌شناس":u"Q212980",
            u"روانشناس":u"Q212980",u"روحانی مسیحی":u"Q2259532",u"روزنامه‌نگار ورزشی":u"Q13219447",u"روزنامه‌نگار":u"Q1930187",u"روشن‌فکر":u"Q58968",u"رویداد نگار":u"Q3330547",
            u"رویدادنگار":u"Q3330547",u"رپ‌خوان":u"Q2252262",u"ریاضی‌دان":u"Q170790",u"زبان‌شناس":u"Q14467526",u"زمین‌شناس":u"Q520549",u"زنبوردار":u"Q852389",
            u"زندگی‌نامه‌نویس":u"Q864380",u"زیست‌شناس دریایی":u"Q3640160",u"زیست‌شناس مولکولی":u"Q15839206",u"زیست‌شناس":u"Q864503",u"زیست شیمیدان":u"Q2919046",
            u"زیست‌شیمیدان":u"Q2919046",u"سفالگر":u"Q7541856",u"سازنده":u"Q6606110",u"ساعت‌ساز":u"Q157798",u"ستاره‌شناس":u"Q11063",u"اخترشناس":u"Q11063",
            u"ستون‌نگار":u"Q1086863",u"سخنران انگیزه‌بخشی":u"Q15982858",u"سخنران انگیزشی":u"Q15982858",u"سخنران عمومی":u"Q12859263",u"سخنران":u"Q9379869",
            u"سرآشپز":u"Q156839",u"سرباز":u"Q4991371",u"سردبیر روزنامه":u"Q17351648",u"سرمایه‌گذار":u"Q557880",u"سرگرم‌کننده":u"Q138858",u"سلحشور":u"Q1250916",
            u"پهلوان":u"Q1250916",u"سنگ‌تراش":u"Q16947657",u"سوارکار":u"Q846750",u"اسب‌سوار":u"Q846750",u"سیاح":u"Q11900058",u"سیاست‌مدار":u"Q82955",
            u"شاعر":u"Q49757",u"شاه":u"Q12097",u"شجره‌شناس":u"Q8963721",u"شطرنج‌باز":u"Q10873124",u"شمشیرباز":u"Q13381863",u"شناگر":u"Q10843402",u"شهردار":u"Q30185",
            u"شوالیه":u"Q102083",u"شیمی‌دان":u"Q593644",u"شیمیدان":u"Q593644",u"صدا پیشه":u"Q2405480",u"صداپیشه":u"Q2405480",u"طبیعت‌شناس":u"Q18805",u"طراح بازی":u"Q3630699",
            u"طراح رقص":u"Q2490358",u"طراح صحنه و لباس":u"Q1323191",u"طراح مد":u"Q3501317",u"طراح":u"Q5322166",u"طنز نویس":u"Q12406482",u"طنزنویس":u"Q12406482",
            u"عارف":u"Q12328016",u"عروسک‌گردان":u"Q2629392",u"عصب‌پژوه":u"Q6337803",u"علوم پرورشی":u"Q7922",u"عکاس":u"Q33231",u"فرماندار":u"Q132050",
            u"فرمانروا":u"Q116",u"فرهنگ‌نویس":u"Q14972848",u"فرهنگ عامه‌شناس":u"Q3075052",u"فروشنده":u"Q215536",u"فضانورد":u"Q11631",u"فعال حقوق بشر":u"Q1476215",
            u"فقیه":u"Q2664701",u"فیزیولوژیست":u"Q2055046",u"فیزیک‌دان":u"Q169470",u"فیزیکدان":u"Q169470",u"فیلسوف":u"Q4964182",u"فیلم‌بردار صحنه":u"Q1208175",
            u"فیلم‌بردار":u"Q222344",u"فیلم‌نامه‌نویس":u"Q28389",u"قاضی":u"Q16533",u"قایقران روئینگ":u"Q13382576",u"قایقران قایق بادبانی":u"Q476246",
            u"قایقران":u"Q13382566",u"قدیس":u"Q43115",u"قصاب":u"Q329737",u"قلم‌زن":u"Q329439",u"لوژسوار":u"Q13382981",u"لوکوموتیوران":u"Q2775569",
            u"مأمور مالیات":u"Q1139055",u"مامور مالیات":u"Q1139055",u"متخصص‌ مالى‌":u"Q1979607",u"متخصص ادبیات":u"Q17167049",u"متخصص اعصاب":u"Q783906",
            u"عصب‌شناس":u"Q783906",u"متخصص الهیات":u"Q1234713",u"متخصص جرم شناسی":u"Q8142883",u"جرم‌شناس":u"Q8142883",u"مترجم":u"Q333634",u"مترون":u"Q1396008",
            u"ویراستار":u"Q1607826",u"مجری تلویزیون":u"Q947873",u"مجری رادیو":u"Q2722764",u"مجری کسب و کار":u"Q2961975",u"مجری":u"Q13590141",u"مجسمه‌ساز":u"Q1281618",
            u"مخترع":u"Q205375",u"مدل":u"Q4610556",u"مدیر عامل اجرایی":u"Q484876",u"مدیر":u"Q2462658",u"مربی بسکتبال":u"Q5137571",u"مربی تیم تنیس":u"Q13219424",
            u"مربی":u"Q41583",u"مردم‌شناس":u"Q1371378",u"مسئول استودیوی ضبط موسیقی":u"Q3089940",u"مشاور":u"Q15978655",u"معلم":u"Q2251335",u"معمار":u"Q42973",
            u"مقاله‌نویس":u"Q11774202",u"ملوان":u"Q45199",u"ملکه":u"Q719039",u"منشی":u"Q80687",u"مهندس برق":u"Q1326886",u"مهندس رایانه":u"Q82594",u"مهندس سازه":u"Q2305987",
            u"مهندس صدا":u"Q128124",u"مهندس صنعت":u"Q2267418",u"مهندس عمران":u"Q13582652",u"مهندس مکانیک":u"Q196721",u"مهندس نرم‌افزار":u"Q1709010",u"مهندس کامپیوتر":u"Q82594",
            u"مهندس کشاورزی":u"Q131512",u"مهندس":u"Q81096",u"مورخ نظامی":u"Q1493121",u"مورخ":u"Q201788",u"موسیقی‌دان":u"Q639669",u"موسیقیدان":u"Q639669",u"مکانیک":u"Q327029",
            u"ناوبر":u"Q254651",u"نسل‌شناس":u"Q3126128",u"نقاش":u"Q1028181",u"نقشه‌برداری":u"Q816425",u"نمایشنامه‌نویس":u"Q214917",u"نمایشگاه‌گردان":u"Q674426",
            u"نمایش‌پردازی":u"Q492537",u"نوازنده پیانو":u"Q486748",u"نوازنده گیتار":u"Q855091",u"نوازنده":u"Q1294626",u"نویسندهٔ داستان کوتاه":u"Q15949613",
            u"داستان کوتاه‌نویس":u"Q15949613",u"نویسنده":u"Q36180",u"هنرمند":u"Q483501",u"هنرپیشه":u"Q33999",u"هواشناس":u"Q1113838",u"هیزم شکن":u"Q1437754",
            u"هیزم‌شکن":u"Q1437754",u"وبلاگ‌نویس":u"Q8246794",u"ورزشکار ده‌گانه":u"Q21141381",u"ورزشکار دوچرخه‌سواری سیکلوکراس":u"Q15117415",u"ورزشکار دو و میدانی":u"Q11513337",
            u"ورزشکار چوگان":u"Q13218361",u"وزنه‌بردار":u"Q13381376",u"وزیر":u"Q1423891",u"وکیل":u"Q40348",u"پادکست‌ساز":u"Q15077007",u"پارتیزان":u"Q212948",
            u"پدیدآور":u"Q482980",u"پرتاب‌گر دیسک":u"Q13381689",u"پرتاب‌گر نیزه":u"Q18510502",u"پرتاب‌گر وزنه":u"Q18534714",u"پرتاب‌گر چکش":u"Q13856320",
            u"پرستار":u"Q186360",u"پرسنل نظامی":u"Q47064",u"پرنده‌شناس":u"Q1225716",u"پزشک متخصص زایمان":u"Q13638192",u"پزشک":u"Q39631",u"پلیس":u"Q384593",
            u"پویانما":u"Q266569",u"پژوهشگر مطالعات قرون وسطا":u"Q3332711",u"پیامبر":u"Q42857",u"پیراروانشناس":u"Q3363630",u"چترباز":u"Q6060450",u"چشم‌پزشک":u"Q12013238",
            u"چهره‌پردازی":u"Q935666",u"چوپان":u"Q152002",u"چین‌شناس":u"Q15255771",u"ژیمناست هنری":u"Q13381572",u"کاخ‌دار":u"Q264323",u"کارآفرین":u"Q131524",u"کاراته‌کا":u"Q9017214",
            u"کارتونیست":u"Q1114448",u"کارشناس سیاسی":u"Q1238570",u"کارمند بانک‌":u"Q806798",u"کارمند":u"Q738142",u"کارگردان":u"Q2526255",u"کاریکاتوریست":u"Q3658608",
            u"کالبد‌شناس":u"Q10872101",u"کتابدار":u"Q182436",u"کتاب‌شناس":u"Q10429346",u"کتاب فروش":u"Q998550",u"کتاب‌فروش":u"Q998550",u"کشاورز":u"Q131512",u"کشتی‌گیر کشتی حرفه‌ای":u"Q13474373",
            u"کشیش محلی":u"Q955464",u"کشیش":u"Q42603",u"کمدین":u"Q245068",u"کوهنورد":u"Q9149093",u"کیمیاگر":u"Q15954519",u"گردشگر":u"Q11900058",u"گزارشگر":u"Q42909",
            u"گلف‌باز":u"Q11303721",u"گوینده اخبار":u"Q270389",u"گیاه‌شناس":u"Q2374149"}

boxes=[u'infobox',u'جعبه']
Temp_black_list=[u'الگو:حذف سریع',u'الگو:سرشناسی',u'الگو:Db-meta',u'الگو:حذف زمان‌دار/پیغام']

def templatequery(page_link):
    Temps=[]
    page_link=page_link.replace(u' ',u'_')
    query_page = pywikibot.data.api.Request(site=faSite, action="query", prop="templates",titles=page_link,redirects=1,tllimit=500)
    query_page=query_page.submit()
    try:
        for i in query_page[u'query'][u'pages']:    
            templateha=query_page[u'query'][u'pages'][i]['templates']
            break
        for temp in templateha:
            Temps.append(temp[u'title'].replace(u'_',u' '))         
        return Temps
    except:
        return []

def Txt2Num (txt):
    #return txt
    txt=txt.replace(u" سی و یکم ",u" 31 ").replace(u" سی و یک ",u" 31 ").replace(u" سیم ",u" 31 ").replace(u" سی‌ام ",u" 30 ")
    txt=txt.replace(u" سی ",u" 30 ").replace(u" بیست و نهم ",u" 29 ").replace(u" بیست و نه ",u" 29 ").replace(u" بیست و هشتم ",u" 28 ")
    txt=txt.replace(u" بیست و هشت ",u" 28 ").replace(u" بیست و هفتم ",u" 27 ").replace(u" بیست و هفت ",u" 27 ").replace(u" بیست و ششم ",u" 26 ")
    txt=txt.replace(u" بیست و شش ",u" 26 ").replace(u" بیست و پنجم ",u" 25 ").replace(u" بیست و پنج ",u" 25 ").replace(u" بیست و چهارم ",u" 24 ")
    txt=txt.replace(u" بیست و چهار ",u" 24 ").replace(u" بیست و سوم ",u" 23 ").replace(u" بیست و سه ",u" 23 ").replace(u" بیست و دوم ",u" 22 ")
    txt=txt.replace(u" بیست و دو ",u" 22 ").replace(u" بیست و یکم ",u" 21 ").replace(u" بیست و یک ",u" 21 ").replace(u" بیستم ",u" 20 ")
    txt=txt.replace(u" بیست ",u" 20 ").replace(u" نوزدهم ",u" 19 ").replace(u" نوزده ",u" 19 ").replace(u" هجدهم ",u" 18 ")
    txt=txt.replace(u" هجده ",u" 18 ").replace(u" هفدهم ",u" 17 ").replace(u" هفده ",u" 17 ").replace(u" شانزدهم ",u" 16 ")
    txt=txt.replace(u" شانزده ",u" 16 ").replace(u" پانزدهم ",u" 15 ").replace(u" پانزده ",u" 15 ").replace(u" چهاردهم ",u" 14 ")
    txt=txt.replace(u" چهارده ",u" 14 ").replace(u" سیزدهم ",u" 13 ").replace(u" سیزده ",u" 13 ").replace(u" دوازدهم ",u" 12 ")
    txt=txt.replace(u" دوازده ",u" 12 ").replace(u" یاردهم ",u" 11 ").replace(u" یارده ",u" 11 ").replace(u" دهم ",u" 10 ")
    txt=txt.replace(u" ده ",u" 10 ").replace(u" نهم ",u" 9 ").replace(u" نه ",u" 9 ").replace(u" هشتم ",u" 8 ")
    txt=txt.replace(u" هشت ",u" 8 ").replace(u" هفتم ",u" 7 ").replace(u" هفت ",u" 7 ").replace(u" ششم ",u" 6 ")
    txt=txt.replace(u" شش ",u" 6 ").replace(u" پنجم ",u" 5 ").replace(u" پنج ",u" 5 ").replace(u" چهارم ",u" 4 ")
    txt=txt.replace(u" چهار ",u" 4 ").replace(u" سوم ",u" 3 ").replace(u" سه ",u" 3 ").replace(u" دوم ",u" 2 ")
    txt=txt.replace(u" دو ",u" 2 ").replace(u" یکم ",u" 1 ").replace(u" یک ",u" 1 ")
    return txt

def Add_date_to_wikidata(data, year,month,day, arg,statedin,precision):
    try:
        items = data.get()
    except:
        return False
    for claim in items['claims']:
        if claim == u'P'+str(arg):
           return False
    repo = faSite.data_repository()

    claim_item = pywikibot.Claim(repo, u'P'+str(arg))#P569

    today=str(datetime.now()).replace('-','').split(' ')[0].strip()
    if year > int(today[:4]):#not to add year more than this year
        pywikibot.output(u'\03{lightred}Year \03{default}'+str(year)+u' \03{lightred}is incorrect so it is passed!\03{default}')
        return False

    target = pywikibot.WbTime(site=repo,year=year, month=month, day=day, precision=precision)#1990-12-1
    claim_item.setTarget(target)
    data.addClaim(claim_item)
    claim_item.addSources([statedin])
    return True

def Add_property_to_wikidata(fapage,Human_Data):
    #fapage = pywikibot.Page(faSite, u'ویکی‌پدیا:صفحه تمرین/ویکی‌داده')#Q4115189
    Human_Data_number={"newcat":000,'#Article_name':000,"Suggested_cat_list":000,"birth_centry":000,"main_category":000,"death_centry":000,
                       "occupation_safe":000 ,"university_safe":000 ,"awards_safe":000 ,"members_safe":000,"birth_date_fa":000,"death_date_fa":000,
                       "members_B":000,"birth_date_pish":000,"gender":21, "nationality":27,"birth_date":569, "death_date":570,
                       "university":69,"awards":166,"members":102,"occupation":106,"birth_place":19}
    try:
        data = pywikibot.ItemPage.fromPage(fapage)
    except:
        pass

    try:
        items = data.get()
    except:
        pywikibot.output(u'It does not item in wikidata')
        data = pywikibot.ItemPage(fapage.site.data_repository())
        data.editEntity({'sitelinks':{'fawiki':{'site': 'fawiki','title': fapage.title()}},'labels':{'fa':{'language': 'fa','value': fapage.title()}}}, summary=u'Bot:Creating new Item from fa.wikipedia')
        items = data.get()

    repo = faSite.data_repository()
    statedin = pywikibot.Claim(repo, u'P143')#درون‌زیزی از
    itis = pywikibot.ItemPage(repo, "Q48952")#ویکی‌پدیای فارسی
    statedin.setTarget(itis)
    # add human

    if not u'P31' in items['claims']:
        claim_item = pywikibot.Claim(repo, u'P31')
        target = pywikibot.ItemPage(repo, "Q5")
        claim_item.setTarget(target)
        data.addClaim(claim_item)
        claim_item.addSources([statedin])
        pywikibot.output(u'\03{lightgreen}The claim انسان is added!\03{default}')
    for i in Human_Data:
        item_num=Human_Data_number[i]
        item_req=Human_Data[i]
        if item_num==000:
            continue
        passport=True
        if item_num==19 and Human_Data["birth_place"]==Human_Data["nationality"]:
            pywikibot.output(u'\03{lightblue}Birth_place = nationality so it will be pass!\03{default}')
        for claim in items['claims']:
            if claim == u'P'+str(item_num):
                pywikibot.output(u'\03{lightblue}P'+str(item_num)+u'\03{default} is repeated claim')
                passport=False
                break

        '''
        for i in ["occupation" ,"university" ,"awards" ,"members"]:
            if Human_Data[i]:
                if not Human_Data[i+u"_safe"]:
                    pywikibot.output(u'Item '+i+u' was \03{lightred}not safe!\03{default} >'+u'-'.join(Human_Data[i])+u' ')
                    Human_Data[i]=[]
        '''
        if type(item_req) is list:
            item_reqs=item_req
            for item_req in item_reqs:
                passport2=True
                target=None
                if item_req:
                    item_req=item_req.replace(u'[[',u'').replace(u']]',u'')
                    if item_req in switch_occ:
                            item_req=switch_occ[item_req]
                    try:
                        req_page = pywikibot.Page(faSite, item_req)
                        req_data = pywikibot.ItemPage.fromPage(req_page)
                        item_req_ID=req_data.getID()
                    except:
                        if item_req in no_link_item:
                            item_req_ID=no_link_item[item_req]
                            target = pywikibot.ItemPage(repo,item_req_ID)
                        else:
                            pywikibot.output(u'\03{lightred}Claim  '+item_req+u' was not existed so it will pass!\03{default}')
                            continue
                    if not passport:
                        our_cases=items['claims'][u'P'+str(item_num)]
                        for claim in our_cases:
                            if claim.getTarget().title()== str(item_req_ID):
                                pywikibot.output(u'The claim '+item_req+u' is repeated!')
                                passport2=False

                    if not passport2:
                        continue
                    claim_item = pywikibot.Claim(repo, u'P'+str(item_num))
                    if not target:
                        try:
                            req_page = pywikibot.Page(faSite, item_req)
                            target = pywikibot.ItemPage.fromPage(req_page)
                        except:
                            pywikibot.output(u'\03{lightred}Claim  '+item_req+u' was not existed so it will pass!\03{default}')
                            continue
                        # --- filtering Q items
                        if item_num==69:
                            if ClaimFinder(faSite,item_req,31,Data2fas=False)!=3918:#دانشگاه
                               pywikibot.output(u'\03{lightred}The claim '+item_req+u' is not a دانشگاه so it will pass!\03{default}')
                               continue
                        #pywikibot.output(u'\03{lightred}The claim '+item_req+u'----item_num='+str(item_num)+u'---'+str(ClaimFinder(faSite,item_req,31,Data2fas=False))+u'---------\03{default}')
                        if item_num==106:
                            if item_req==u'مهندس':
                               pywikibot.output(u'\03{lightred}This bot do not add مهندس so it will pass!\03{default}')
                               continue
                            if item_req==u"پاپ":
                               pywikibot.output(u'\03{lightred}This bot do not add پاپ so it will pass!\03{default}')
                               continue
                            if ClaimFinder(faSite,item_req,31,Data2fas=False)==28640 or ClaimFinder(faSite,item_req,31,Data2fas=False)==13516667 or ClaimFinder(faSite,item_req,31,Data2fas=False)==1914636:#حرفه-شغل-فعالیت
                               pass
                            elif ClaimFinder(faSite,item_req,425,Data2fas=False):
                               continue
                            else:
                               pywikibot.output(u'\03{lightred}The claim '+item_req+u' is not a حرفه so it will pass!\03{default}')
                               continue

                        if item_num==166:
                            if not u'جایزه' in ClaimFinder(faSite,item_req,31):#جایزه
                               pywikibot.output(u'\03{lightred}The claim '+item_req+u' is not a جایزه so it will pass!\03{default}')
                               continue

                        if item_num==102:
                            if ClaimFinder(faSite,item_req,31,Data2fas=False)==7278 or ClaimFinder(faSite,item_req,31,Data2fas=False)==1393724:#حزب
                               pass
                            else:
                               pywikibot.output(u'\03{lightred}The claim '+item_req+u' is not a حزب so it will pass!\03{default}')
                               continue
                    claim_item.setTarget(target)
                    data.addClaim(claim_item)
                    claim_item.addSources([statedin])
                    pywikibot.output(u'\03{lightgreen}The claim '+item_req+u' is added!\03{default}')
                    pywikibot.output(u'\03{lightgreen}The claim '+item_req+u' is added!\03{default}')

        elif item_num==569 or item_num==570:
            if not passport:
                continue
            #wikipedia.output('>>>'+item_req)
            if u'-' in item_req:
                year=item_req.split(u'-')[0]
                month=item_req.split(u'-')[1]
                day=item_req.split(u'-')[2]
                precision=item_req.split(u'-')[3]
                if (precision==u'9') or (day==u'۰۰' and month==u'۰۰') or (day==u'۰' and month==u'۰') or (day==u'' and month==u''):
                    precision='year'
                    month=u'01'
                    day=u'01'
                elif precision==u'10' or (day==u'۰۰' and month!=u'۰۰') or (day==u'۰' and month!=u'۰') or (day==u'' and month!=u''):
                    precision='month'
                    day=u'01'
                else:
                    precision='day'
                try:
                    results_date=Add_date_to_wikidata(data, int(Fa2En_num(year)),int(Fa2En_num(month)),int(Fa2En_num(day)), item_num,statedin,precision)
                except:
                    results_date=Add_date_to_wikidata(data, int(Fa2En_num(year)),int(Fa2En_num(month)),int(Fa2En_num(day)), item_num,statedin,precision)
                if results_date:
                    pywikibot.output(u'\03{lightgreen}The claim '+item_req+u' is added!\03{default}')

            else:
                if not item_req.strip():
                    if item_num==569:
                        pywikibot.output('\03{lightred}Birth date is not existed!\03{default}')
                    else:
                        pywikibot.output('\03{lightred}Death date is not existed!\03{default}')
                else:
                    pywikibot.output(u'\03{lightred}The P'+str(item_num)+' is '+item_req+u' and not standard!\03{default}')
        elif item_num==21:
            if not passport:
                #male animal (Q44148)
                #female animal (Q43445)
                claim21=items['claims']['P21'][0].getTarget().title()
                if claim21==u'Q44148':
                    item_req_ID=u'Q6581097'
                    pywikibot.output(u'\03{lightblue}> > start changing '+claim21+u' to '+item_req_ID+u'\03{default}')
                elif claim21==u'Q43445':
                    item_req_ID='Q6581072'
                    pywikibot.output(u'\03{lightblue}> > start changing '+claim21+u' to '+item_req_ID+u'\03{default}')
                else:
                    if claim21==u'Q6581097' or claim21==u'Q6581072':
                        continue
                    else:
                        pywikibot.output(u'\03{lightred}I do not know what was P21!! ('+claim21+u') \03{default}')
                        continue
                data.removeClaims(data.claims['P21'])
                claim_item = pywikibot.Claim(repo, u'P21')
                target = pywikibot.ItemPage(repo,item_req_ID)
                claim_item.setTarget(target)
                data.addClaim(claim_item)
                claim_item.addSources([statedin])
                pywikibot.output(u'\03{lightblue} > > The claim was '+claim21+u' and it is switched to '+item_req_ID+u' !\03{default}')
            else:    
                if item_req:
                    if item_req==u'مذکر':
                        item_req_ID='Q6581097'
                    else:
                        item_req_ID='Q6581072'
                    claim_item = pywikibot.Claim(repo, u'P21')
                    target = pywikibot.ItemPage(repo,item_req_ID)
                    claim_item.setTarget(target)
                    data.addClaim(claim_item)
                    claim_item.addSources([statedin])
                    pywikibot.output(u'\03{lightgreen}The claim '+item_req+u' is added!\03{default}')
        else:
            if not passport:
                continue
            if item_req:
                claim_item = pywikibot.Claim(repo, u'P'+str(item_num))
                try:
                    req_page = pywikibot.Page(faSite, item_req.replace(u'[[',u'').replace(u']]',u'').strip())
                    target = pywikibot.ItemPage.fromPage(req_page)
                except:
                    continue
                claim_item.setTarget(target)
                data.addClaim(claim_item)
                claim_item.addSources([statedin])
                pywikibot.output(u'\03{lightgreen}The claim '+item_req+u' is added!\03{default}')

def Check_Page_Exists(page_link):
    page_link=page_link.replace(u' ',u'_')
    query_page = pywikibot.data.api.Request(site=faSite, action="query", prop="info",titles=page_link)
    query_page=query_page.submit()
    try:
        for i in query_page[u'query'][u'pages']:    
            redirect_link=query_page[u'query'][u'pages'][i]['pageid']  
            return True# page existed
    except:
        return False# page not existed

def En2Fa_num (txt):
    try:
       txt=str(txt)
    except:
       pass
    count=0
    for i in u'۰۱۲۳۴۵۶۷۸۹':
       txt=txt.replace(str(count),i)
       count+=1
    txt=txt.replace(u',',u'،')
    return txt

def Fa2En_num (txt):
    try:
       txt=str(txt)
    except:
       pass
    count=0
    for i in u'۰۱۲۳۴۵۶۷۸۹':
       txt=txt.replace(i,str(count))
       count+=1
    return txt

def Normalizing_num(txt):
    count=0
    for i in txt:
        if i!=u'۰':
          break
        count+=1
    txt=txt[count:]
    return txt

def Boxfind(text_en):
    text_en=text_en.replace(u'{{ ',u'{{').replace(u'{{ ',u'{{').replace(u'{{template:',u'{{').replace(u'{{Template:',u'{{')
    lines=text_en.split('\n')
    start=False    
    box=u'\n'
    diff=1
    linebaz,linebasteh=0,0
    for our_box in boxes:
        our_box=our_box.strip()
        up_our_box=our_box[0].upper()+our_box[1:]
        lower_our_box=our_box[0].lower()+our_box[1:]
        for line in lines:
            if line==u'':
                continue
            if line.find(u'{{'+lower_our_box)!=-1 :# lower case    
                start=True
                linebaz,linebasteh=0,0
                box+=u'{{'+lower_our_box+line.split(u'{{'+lower_our_box)[1]+u'\n'
                linebaz += string.count( line,"{{" )
                linebasteh += string.count( line,"}}" )    
                diff=linebaz-linebasteh
                continue
            if line.find(u'{{'+up_our_box)!=-1 :# upper case
                start=True
                linebaz,linebasteh=0,0
                box+=u'{{'+up_our_box+line.split(u'{{'+up_our_box)[1]+'\n'
                linebaz += string.count( line,"{{" )
                linebasteh += string.count( line,"}}" )
                diff=linebaz-linebasteh
                continue
            if start==True and diff!=0:
                linebaz += string.count( line,"{{" )
                linebasteh += string.count( line,"}}" )
                diff=linebaz-linebasteh
                box+=line+'\n'
            if diff==0 and start==True:
                break
    return box

def Get_box (fa_text):
    my_box=Boxfind(fa_text)

    if my_box.strip():
        return my_box
    fa_text=fa_text.replace(u'\r',u'')
    lines=fa_text.split('\n')
    matn=' '
    for line in lines:
        linebaz=string.count(line,'{{')
        linebaste=string.count(line,'}}')
        diff=linebaz-linebaste
        if diff==0:
            line=line.replace('{{','$AAAA$').replace('}}','!BBBB!')
        linebaz=0
        linebaste=0
        matn+=line+u'\n'
    my_box=''
    for our_box in boxes:
        our_box=our_box.strip()
        try:
            my_box= re.search(ur'(\{\{\s*['+our_box[0].lower()+our_box[0].upper()+ur']'+our_box[1:]+ur'[_\s](?:\{\{.*?\}\}|[^\}])*\}\})',matn, re.S).group(1)# if Template box has other name please chang this regex
            my_box=my_box.replace(u'$AAAA$',u'{{').replace(u'!BBBB!',u'}}')
            break
        except:
            continue
    if not my_box.strip():
        return u''
    return my_box

def Get_box_items (my_box,cases,multy=False):
    item=u''
    my_box=my_box.lower()
    for case in cases:
        if u'|'+case+u'=' in my_box:
            item=my_box.split(u'|'+case+u'=')[1].split(u'\n')[0]
            if not re.sub(ur'[a-zA-z0-9\,\(\)\"\'\#\@\_\s\*\[\]\>\<\?\!\.\{\}\:]',u'',item).strip():
                item=u''
            if item.strip():
               break
    if not multy:
        if u']]' in item:
            if string.count(item,']]')==2:
                if not re.sub(ur'\[\[.*?\]\]',u'',item).replace(u'،',u'').replace(u'-',u'').strip():
                    item=item.replace(u'[[',u'').replace(u']]',u'').strip()
                    return item
        if u'[[' in item:
            item=item.split(u'[[')[1].split(u'|')[0].split(u']]')[0].strip()
        item=item.split(u']]')[0].replace(u'[[',u'').replace(u']]',u'').strip()
        
        if item:
            if item[-1]==u'،' or item[-1]==u'.' or item[-1]==u'-' or item[-1]==u'؛':
                item=item[:-1]
    else:
        item=item.split(u'}}')[0]
    return item

def Clean_box(my_box):
    if my_box.strip():
        my_box=my_box.replace(u'&nbsp;',u' ').replace(u'{{PAGENAME}}',u' ')
        my_box=my_box.replace(u'<br />',u'،').replace(u'<br/ >',u'،').replace(u'<br/>',u'،').replace(u'<br>',u'،').replace(u'</br>',u'،').replace(u'< /br>',u'،').replace(u'</ br>',u'،')
        my_box=my_box.replace(u'{{سخ}}',u'،').replace(u'{{سرخط}}',u'،').replace(u'   ',u' ').replace(u'  ',u' ').replace(u'= ',u'=')
        my_box=re.sub(ur'(\|.*?\=([\s]|)\n)',ur"", my_box)
        cases=re.findall(ur'(\=(\s|)(\{\{\s*(?:\{\{.*?\}\}|[^\}])*\}\}))',my_box)
        for i in cases:
            case=i[0].replace(u'\n',u'')
            my_box=my_box.replace(i[0],case)
        my_box=re.sub(ur'(\<ref(.*?)\/ref\>)',ur"", my_box)
        my_box=re.sub(ur'(\<small\>(.*?)\<\/small\>)',ur"", my_box)
        my_box=re.sub(ur'(\|.*?\=([\s]|)\n)',ur"", my_box)
        my_box=re.sub(ur'(\<\!\-\- .*? \-\-\>)',ur"", my_box)
        my_box=re.sub(ur'(\<ref(.*?)\/\>)',ur"", my_box)

        my_box=my_box.replace(u']]s ',u']] ')
        my_box=my_box.replace(u'\t',u' ').replace(u'\r',u'')
        my_box=re.sub(ur'(\[\[([fF]ile|پرونده|[Ii]mage)\:.*?\]\])',ur"", my_box)
        for i in range(0,10):
            my_box=my_box.replace(u'   ',u' ').replace(u'  ',u' ').replace(u'،،',u'،')
        my_box=my_box.replace(u'\n ',u'\n').replace(u' \n',u'\n').replace(u' |',u'|').replace(u'| ',u'|').replace(u' =',u'=').replace(u'= ',u'=')
        my_box=my_box.replace(u'|\n',u'\n|').replace(u'\n\n\n',u'\n\n')
        my_box=my_box.replace(u'{{flagicon|',u'').replace(u'{{Flagicon|',u'').replace(u'{{FlagIcon|',u'').replace(u'{{پرچم|',u'').replace(u'{{پرچمک|',u'').replace(u'{{flag|',u'').replace(u'{{Flag|',u'')
        my_box=my_box.replace(u'{{Flagcountry|',u'').replace(u'{{flagcountry|',u'').replace(u'{{FlagCountry|',u'')
        for link in my_box.split(u'[['):
            my_box=my_box.replace(u'[['+link.split(u']]')[0]+u']]',u'[['+link.split(u'|')[0].split(u']]')[0]+u']]')

    else:
        pywikibot.output(u'\03{lightred}---There is no box!\03{default}')
    return my_box

def Find_nation (birth_place,nationality,catfa,my_box,Human_Data):
    nationality=Human_Data["nationality"]
    cat_fa_List=Human_Data["Suggested_cat_list"].replace(u':',u': ').replace(u']]',u' ]]').replace(u'[[',u'[[ ')
    if not nationality:
        for county in countries:
            fa_country=countries[county]
            if not nationality and (u' اهل '+fa_country+u' ' in  cat_fa_List or u' اهالی '+fa_country+u' ' in cat_fa_List):
                return fa_country

    if not birth_place and my_box:
        birth_place=Get_box_items (my_box,[u'محل زندگی',u'محل_زندگی'])
    birth_nationality=ClaimFinder(faSite,birth_place,17)
    if ClaimFinder(faSite,birth_nationality,31)==u'کشور':
        if birth_nationality:
            return birth_nationality
    for county in countries:
        fa_country=countries[county]
        if u' '+fa_country+u' ' in u' '+nationality+u' ':
            return fa_country
        if u' '+fa_country+u'ی ' in u' '+nationality+u'ی ':
            return fa_country
        if u' '+fa_country+u'ایی ' in u' '+nationality+u'ایی ':
            return fa_country
        if u' '+fa_country+u' ' in u' '+birth_place+u' ':
            return fa_country
        if u' '+county+u' ' in u' '+nationality+u' ':
            return fa_country
        if u' '+fa_country+u' ' in u' '+catfa+u' ':
            return fa_country
    return nationality

def Date_cleaner(year,month,day,checking_temp=False,only_year=True):
    if month==0 and day==0:
        only_year=True
        month=1
        day=1
    else:
        only_year=False

    txt=year
    year_en=u''
    txt=u' '+txt+u' '
    txt=Txt2Num (txt)
    txt=Fa2En_num(txt)
    if (u' یا ' in txt) and not checking_temp:
        txt=txt.split(u' یا ')[1]
    txt2=u' '+txt.replace(u'(',u' ').replace(u')',u' ').replace(u'[[',u'[[ ').replace(u']]',u' ]]').replace(u'.',u' ').replace(u'،',u' ').replace(u'‌',u' ').replace(u'  ',u' ')+u' '
    it_is_jalaly,it_is_gregorian=False,False
    if not checking_temp:
        pywikibot.output(u'-------------year='+txt2)
        for per_month in persian_month:
            if u' '+per_month+u' ' in txt2:
                it_is_jalaly=True
                day=txt.split(per_month)[0].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'').strip()
                month=persian_month[per_month]
                txt=txt.split(per_month)[1].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'')
                pywikibot.output(u'-------------day='+day+u'month='+str(month)+u'year='+txt)
                only_year=False
                break
        if not it_is_jalaly:
            for Geryg_month in Gerygorian_month:
                if u' '+Geryg_month+u' ' in txt2:
                    it_is_gregorian=True
                    day=txt.split(u' '+Geryg_month+u' ')[0].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'').strip()
                    month=Gerygorian_month[Geryg_month]
                    txt=txt.split(u' '+Geryg_month+u' ')[1].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'')
                    #pywikibot.output(u'-------------day='+day+u'month='+str(month)+u'year='+txt)
                    only_year=False
                    break

        txt=txt.split(u'/')[0].split(u"\\")[0].replace(u'  ',u' ').replace(u'حدود',u'')
        if (not it_is_jalaly) and (not it_is_gregorian):
            #pywikibot.output(u'checking ghamary')
            if ((u' قمری ' in txt2) or (u' ه ق ' in txt2)):
                txt=txt.split(u'هجری قمری')[0].split(u'قمری')[0].split(u'ه. ق.')[0].split(u'ه ق')[0].split(u'ه‌ق')[0].split(u'(')[0]
                txt=re.sub(ur'[ضصثقفغعهخحجچشسیبلاتنمکگظطزرذآدپو\}\{\<\>\(\)\،\-\:\,\|\)]', " ",txt)
                txt=txt.strip().replace(u'    ',u' ').replace(u'   ',u' ').replace(u'  ',u' ').replace(u'  ',u' ').strip()
                try:
                    day=int(day)
                except:
                    if re.sub(ur'0123456789۱۲۳۴۵۶۷۸۹۰',u'',day).strip():
                        return '',''
                    day=day
                try:
                    month=int(month)
                except:
                    month=month
                if len(txt)>2 and len(txt)<5 and not u'.' in txt:
                    try:
                        islamic_year=int(Fa2En_num (txt))
                    except:
                        return '',''
                    date_extend=''
                    if not month:
                       month=1
                       date_extend=u'-9'
                    if not day:
                       day =1
                       date_extend=u'-10'
                    year_en,month_en,day_en=cal.jd_to_gregorian(cal.islamic_to_jd(islamic_year, month, day))
                    if not only_year:
                        if not date_extend:
                            date_extend=u'-11'
                        if date_extend==u'-10':
                            day_en=00
                        year_en=str(year_en)+u'-'+str(month_en)+u'-'+str(day_en)+date_extend
                    else:
                        year_en=str(year_en)+u'-00-00-9'
                    pywikibot.output(u'\03{lightpurple}date converted Islamic to gregorian > '+str(islamic_year)+u' to '+year_en+u'\03{default}')
                else:
                    return '',''

        if (not year_en) and (not it_is_gregorian):
            #pywikibot.output(u'-----------checking jalaly'+txt)
            if ((u' جلالی ' in txt2) or (u' ه ش ' in txt2) or (u'شمسی' in txt2) or (u'خورشیدی' in txt2)) or it_is_jalaly:
                txt=txt.split(u'هجری شمسی')[0].split(u'شمسی')[0].split(u'ه. ش.')[0].split(u'ه ش')[0].split(u'ه‌ش')[0].split(u'جلالی')[0].split(u'خورشیدی')[0].split(u'(')[0]
                txt=re.sub(ur'[ضصثقفغعهخحجچشسیبلاتنمکگظطزرذآدپو\}\{\<\>\(\)\،\-\,\|\:\)]', " ",txt)
                txt=txt.strip().replace(u'    ',u' ').replace(u'   ',u' ').replace(u'  ',u' ').replace(u'  ',u' ').strip()
                try:
                    day=int(day)
                except:
                    if re.sub(ur'0123456789۱۲۳۴۵۶۷۸۹۰',u'',day).strip():
                        return '',''
                    day=day
                try:
                    month=int(month)
                except:
                    month=month
                if len(txt)>2 and len(txt)<5 and not u'.' in txt:
                    try:
                        persian_year=int(Fa2En_num (txt))
                    except:
                        return '',''
                    date_extend=''
                    if not month:
                       month=1
                       date_extend=u'-9'
                    if not day:
                       day =1
                       date_extend=u'-10'
                    pywikibot.output(u'persian_year='+str(persian_year))
                    pywikibot.output(u'month='+str(month))
                    pywikibot.output(u'day='+str(day))
                    year_en,month_en,day_en=cal.jd_to_gregorian(cal.jalali_to_jd(persian_year, month, day))
                    if not only_year:
                        if not date_extend:
                            date_extend=u'-11'
                        if date_extend==u'-10':
                            day_en=00
                        year_en=str(year_en)+u'-'+str(month_en)+u'-'+str(day_en)+date_extend
                    else:
                        year_en=str(year_en)+u'-00-00-9'
                    pywikibot.output(u'\03{lightpurple}date converted Persian to gregorian > '+str(persian_year)+u' to '+year_en+u'\03{default}')
                else:
                     return '',''

    if (not year_en) and (not it_is_jalaly):
        #pywikibot.output(str(it_is_jalaly)+u'checking gregorian'+txt2)
        if ((u' میلادی ' in txt2) or (u' پ م ' in txt2) or (u' ق م ' in txt2) or  (u' پیش از میلاد ' in txt2) or  (u' قبل از میلاد ' in txt2) or  (u' بعد از میلاد ' in txt2) or checking_temp) or it_is_gregorian:
            if not checking_temp:
                txt=txt.split(u'میلادی')[0].split(u'پ. م.')[0].split(u'پ‌م')[0].split(u'ق‌م')[0].split(u'ق. م.')[0].split(u'ق م')[0].split(u'پ م')[0]
                txt=txt.split(u'پیش از میلاد')[0].split(u'قبل از میلاد')[0].split(u'(')[0]
                txt=re.sub(ur'[ضصثقفغعهخحجچشسیبلاتنمکگظطزرذآدپو\}\{\<\>\(\)\،\-\:\,\|\)]', " ",txt)
                txt=txt.strip().replace(u'    ',u' ').replace(u'   ',u' ').replace(u'  ',u' ').replace(u'  ',u' ').strip()
                try:
                    day_en=str(day)
                except:
                    day_en=day
                try:
                    month_en=str(month)
                except:
                    month_en=month
                if len(txt)>2 and len(txt)<5 and not u'.' in txt:
                    try:
                        year_en=str(int(Fa2En_num (txt)))# checking is it number
                    except:
                        return '',''
                    date_extend=''
                    if not month:
                       month_en=u'00'
                       date_extend=u'-9'
                    if not day:
                       day_en =u'00'
                       date_extend=u'-10'
                    if not only_year:
                        if not date_extend:
                            date_extend=u'-11'
                        if date_extend==u'-10':
                            day_en=u'00'
                        year_en=year_en+u'-'+month_en+u'-'+day_en+date_extend
                    else:
                        year_en=year_en+u'-00-00-9'
                    pywikibot.output(u'\03{lightpurple}date is gregorian > '+year_en+u'\03{default}')
                else:
                     return '',''
            else:
                year_en=year+u'-'+month+u'-'+day+u'-11'
    pish=False

    if (u' پ م ' in txt2) or (u' ق م ' in txt2) or  (u' پیش از میلاد ' in txt2) or  (u' قبل از میلاد ' in txt2):
        pish=True

    if not year_en:
        txt=txt.replace(u'[[',u'').replace(u']]',u'').strip()
        try:
            txt=Fa2En_num(txt)
            if len(txt)>2 and len(txt)<5 and not u'.' in txt:
                year_fa=int(txt)
                year_en,month_en,day_en=cal.jd_to_gregorian(cal.jalali_to_jd(year_fa, 01, 01))
                year_en=str(year_en)+u'-00-00-9'
            else:
                pass
        except:
           pass
    return year_en,pish

def Find_birth_place(Human_Data,my_box):
    birth_place=Human_Data["birth_place"]
    nationality=Human_Data["nationality"]
    cat_fa_List=Human_Data["Suggested_cat_list"].replace(u':',u': ').replace(u']]',u' ]]').replace(u'[[',u'[[ ')
    #linebaste=string.count(line,'}}')
    if not birth_place:
        if u' اهالی ' in cat_fa_List:
            birth_place=cat_fa_List.split(u' اهالی ')[1].split(u']]')[0].strip()
            if string.count(cat_fa_List,u' اهالی ')>1 and (u'استان' in birth_place or u'شهرستان' in birth_place or u'ایالت' in birth_place or nationality==birth_place):
                birth_place=cat_fa_List.split(u' اهالی ')[2].split(u']]')[0].strip()
        if not birth_place.strip():
            if u' اهل ' in cat_fa_List:
                birth_place=cat_fa_List.split(u' اهل ')[1].split(u']]')[0].strip()
                if string.count(cat_fa_List,u' اهل ')>1 and (u'استان' in birth_place or u'شهرستان' in birth_place or u'ایالت' in birth_place or nationality==birth_place):
                    birth_place=cat_fa_List.split(u' اهل ')[2].split(u']]')[0].strip()
        if u'استان' in birth_place or u'شهرستان' in birth_place or u'ایالت' in birth_place or nationality==birth_place:
            birth_nationality=ClaimFinder(faSite,birth_place,17)
            if ClaimFinder(faSite,birth_nationality,31)==u'کشور':
                if birth_nationality and not nationality:
                    Human_Data["nationality"]=birth_nationality
                    nationality=birth_nationality
            birth_place=u''

        if birth_place!=nationality:
            if nationality:
                Human_Data["birth_place"]=birth_place
                birth_place_old=birth_place
            else:
                nationality=Find_nation (birth_place,nationality,Human_Data["Suggested_cat_list"],my_box,Human_Data)
                if birth_place!=nationality and nationality:
                    Human_Data["birth_place"]=birth_place
                    birth_place_old=birth_place
        else:
            birth_place=Human_Data["birth_place"]
    birth_place_old=birth_place

    if not nationality.strip():
        nationality=Find_nation (birth_place_old,nationality,Human_Data["Suggested_cat_list"],my_box,Human_Data)
        nationality=re.sub(ur'\{\{.*?\}\}',u'',nationality).strip()
        Human_Data["nationality"]=nationality

    if not nationality.strip() and birth_place:
        birth_nationality=ClaimFinder(faSite,birth_place,17)
        if ClaimFinder(faSite,birth_nationality,31)==u'کشور':
            if birth_nationality and not nationality:
                Human_Data["nationality"]=birth_nationality
                nationality=birth_nationality

    return Human_Data

def Find_occupation(my_box,fa_text):
    occupation=u''
    Templates=[u'{{Infobox',u'{{infobox',u'{{جعبه اطلاعات',u'{{جعبه_اطلاعات']
    for i in Templates:
        if i in my_box:
           occupation=my_box.split(i)[1].split(u'\n')[0].split(u'|')[0].replace(u'_',u' ').strip()
           break
    if not occupation:
        if u'-خرد}}' in fa_text:
            RE=re.compile(ur'(\{\{.*?\-خرد\}\})')
            khords=RE.findall(fa_text)
            for i in khords:
                i=i.replace(u'-خرد}}',u'').replace(u'{{',u'').replace(u'_',u' ').strip()
                if i in switch_occ:
                     i=switch_occ[i]
                if ClaimFinder(faSite,i,31,Data2fas=False)==28640 or ClaimFinder(faSite,i,31,Data2fas=False)==13516667 or ClaimFinder(faSite,i,31,Data2fas=False)==1914636:# or ClaimFinder(faSite,i,425,Data2fas=False):#حرفه
                    return [i]
                else:
                    pywikibot.output(u'\03{lightgree}Occupation found by template= '+i+u' is not a حرفه so it will pass!\03{default}')
                    continue
    if occupation in switch_occ:
        occupation=switch_occ[occupation]
    if ClaimFinder(faSite,occupation,31,Data2fas=False)==28640 or ClaimFinder(faSite,occupation,31,Data2fas=False)==13516667 or ClaimFinder(faSite,occupation,31,Data2fas=False)==1914636:# or ClaimFinder(faSite,occupation,425,Data2fas=False):#حرفه
        return [occupation]
    else:
        pywikibot.output(u'\03{lightgree}Occupation found by template= '+occupation+u' is not a حرفه so it will pass!\03{default}')
        return []

def Article_is_human_box(fa_text,Human_Data):
    jalaly_date=False
    my_box=Get_box (fa_text)
    my_box=Clean_box(my_box)
    pywikibot.output(my_box)
    if not my_box:
        return Human_Data,my_box
    birth_place=Human_Data["birth_place"]
    if not birth_place:
        birth_place_old=Get_box_items (my_box,[u'محل تولد',u'birth_place',u'زادگاه',u'شهر تولد',u'محل_تولد'])
        Human_Data["birth_place"]=birth_place_old
    else:
        birth_place_old=birth_place

    Human_Data=Find_birth_place(Human_Data,u'')
    birth_place=Human_Data["birth_place"]
    nationality=Human_Data["nationality"]
    if not nationality:
        nationality=Get_box_items (my_box,[u'ملیت',u'تابعیت',u'nationality',u'کشور تولد',u'کشور',u'origin'],False).replace(u'{{',u'').replace(u'}}',u'')
        if u'ایران' in  nationality or 'iran' in  nationality:
            nationality=u'ایران'
            jalaly_date=True
        elif u'افغان' in  nationality:
            nationality=u'افغانستان'
            jalaly_date=True
        elif u'تاجیک' in  nationality:
            nationality=u'تاجیکستان'
            jalaly_date=True
        else:
            nationality=Find_nation (birth_place_old,nationality,Human_Data["Suggested_cat_list"],my_box,Human_Data)
        nationality=re.sub(ur'\{\{.*?\}\}',u'',nationality).strip()
        Human_Data["nationality"]=nationality
    #---------finding nationality from birth_place final solution---------
    if not nationality.strip():
        birth_nationality=ClaimFinder(faSite,birth_place,17)
        if ClaimFinder(faSite,birth_nationality,31)==u'کشور':
            if birth_nationality:
                nationality= birth_nationality
        Human_Data["nationality"]=nationality

    if Human_Data["birth_date"] and (nationality==u'ایران' or nationality==u'افغانستان' or nationality==u'تاجیکستان'):
        birth_date_fa=Get_box_items (my_box,[u'تاریخ تولد',u'birth_date',u'زادروز',u'تاریخ_تولد',u'تولد']).replace(u'_',u' ')
        birth_date_fa=birth_date_fa.replace(u'|mf=yes',u'').replace(u'|mf=no',u'').replace(u'|mf=Yes',u'').replace(u'|mf=No',u'')
        if len(birth_date_fa)!=4:
            if (u' یا ' in birth_date_fa):
                    birth_date_fa=birth_date_fa.split(u' یا ')[1]
            birth_date_fa_2=u' '+birth_date_fa.replace(u'(',u' ').replace(u')',u' ').replace(u'[[',u'[[ ').replace(u']]',u' ]]').replace(u'.',u' ').replace(u'،',u' ').replace(u'‌',u' ').replace(u'  ',u' ')+u' '
            for per_month in persian_month:
                if u' '+per_month+u' ' in birth_date_fa_2:
                    birth_date_fa=birth_date_fa.split(per_month)[1].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'').strip()
                    break
        try:
            birth_date_fa_num=int(En2Fa_num(birth_date_fa))
            if len(birth_date_fa)!=4:
                birth_date_fa=Human_Data["birth_date"]
        except:
            birth_date_fa=Human_Data["birth_date"]
        Human_Data["birth_date_fa"]=birth_date_fa
        pywikibot.output(u'------------->> birth_date_fa='+birth_date_fa)

    if not Human_Data["birth_date"]:
        box_date=Get_box_items (my_box,[u'تاریخ تولد',u'birth_date',u'زادروز',u'تاریخ_تولد',u'تولد']).replace(u'_',u' ')
        box_date=box_date.replace(u'|mf=yes',u'').replace(u'|mf=no',u'').replace(u'|mf=Yes',u'').replace(u'|mf=No',u'')
        if (u'{{تولد' in box_date or u'{{تاریخ'  in box_date or u'{{سن' in box_date or u'{{Birth' in box_date or u'{{Age' in box_date) and not jalaly_date:
            year=box_date.split(u'|')[1]
            try:
                month=box_date.split(u'|')[2]
                day=box_date.split(u'|')[3].split(u'|')[0].split(u'}')[0]
                only_year=False
            except:
                month,day=0,0
                only_year=True
            birth_date,birth_date_pish=Date_cleaner(year,month,day,True,only_year)
        else:
            birth_date,birth_date_pish=Date_cleaner(box_date,0,0,False,True)
        Human_Data["birth_date"]=En2Fa_num (birth_date).replace(u'{{',u'').replace(u'}}',u'')
        Human_Data["birth_date_pish"]=birth_date_pish

        if not Human_Data["birth_centry"]:
            if birth_date:
                birth_year=birth_date.split(u'-')[0].strip()
                if not birth_date_pish:
                    birth_centry=u'سده '+str((int(birth_year)/100)+1).split(u'.')[0]+u' (میلادی)'
                else:
                    birth_centry=u'سده '+str((int(birth_year)/100)+1).split(u'.')[0]+u' (پیش از میلاد)'
                Human_Data["birth_centry"]=En2Fa_num (birth_centry)
    if Human_Data["death_date"] and (nationality==u'ایران' or nationality==u'افغانستان' or nationality==u'تاجیکستان'):
        death_date_fa=Get_box_items (my_box,[u'تاریخ مرگ',u'death_date',u'تاریخ درگذشت',u'تاریخ_مرگ',u'مرگ']).replace(u'_',u' ')
        death_date_fa=death_date_fa.replace(u'|mf=yes',u'').replace(u'|mf=no',u'').replace(u'|mf=Yes',u'').replace(u'|mf=No',u'')
        if len(death_date_fa)!=4:
            if (u' یا ' in death_date_fa):
                    death_date_fa=death_date_fa.split(u' یا ')[1]
            death_date_fa_2=u' '+death_date_fa.replace(u'(',u' ').replace(u')',u' ').replace(u'[[',u'[[ ').replace(u']]',u' ]]').replace(u'.',u' ').replace(u'،',u' ').replace(u'‌',u' ').replace(u'  ',u' ')+u' '
            for per_month in persian_month:
                if u' '+per_month+u' ' in death_date_fa_2:
                    death_date_fa=death_date_fa.split(per_month)[1].split(u'،')[0].split(u',')[0].split(u'(')[0].replace(u'[[',u'').replace(u']]',u'').strip()
                    break
        try:
            death_date_fa_num=int(En2Fa_num(death_date_fa))
            if len(death_date_fa)!=4:
                death_date_fa=Human_Data["death_date"]
        except:
            death_date_fa=Human_Data["death_date"]
        Human_Data["death_date_fa"]=death_date_fa
        pywikibot.output(u'------------->> death_date_fa='+death_date_fa)

    if not Human_Data["death_date"]:
        box_date=Get_box_items (my_box,[u'تاریخ مرگ',u'death_date',u'تاریخ درگذشت',u'تاریخ_مرگ',u'مرگ']).replace(u'_',u' ')
        box_date=box_date.replace(u'|mf=yes',u'').replace(u'|mf=no',u'').replace(u'|mf=Yes',u'').replace(u'|mf=No',u'')
        if (u'{{مرگ' in box_date or u'{{تاریخ'  in box_date or u'{{Death' in box_date or u'{{Age' in box_date) and not jalaly_date:
            
            year=box_date.split(u'|')[1]
            try:
                month=box_date.split(u'|')[2]
                day=box_date.split(u'|')[3].split(u'|')[0].split(u'}')[0]
                only_year=False
            except:
                month,day=0,0
                only_year=True
            death_date,death_date_pish=Date_cleaner(year,month,day,True,only_year)
        else:
            death_date,death_date_pish=Date_cleaner(box_date,0,0,False,True)
        Human_Data["death_date"]=En2Fa_num (death_date).replace(u'{{',u'').replace(u'}}',u'')
        if not Human_Data["death_centry"]:
            if death_date:
                death_year=death_date.split(u'-')[0].strip()
                if not death_date_pish:                        
                    death_centry=u'سده '+str((int(death_year)/100)+1).split(u'.')[0]+u' (میلادی)'
                else:
                    death_centry=u'سده '+str((int(death_year)/100)+1).split(u'.')[0]+u' (پیش از میلاد)'
                Human_Data["death_centry"]=En2Fa_num (death_centry)

    #---------occupation--------
    occupation=Get_box_items (my_box,[u'پیشه',u'occupation',u'زمینه فعالیت',u'شغل',u'زمینه‌های فعالیت'],True)
    occupation,it_is_safe=Multy_link_clean(occupation)
    occupation_remove=[]
    if not occupation:
        occupation=Find_occupation(my_box,fa_text)
    
    for i in occupation:
        i=i.replace(u'[[',u'').replace(u']]',u'').strip()
        if i in switch_occ:
            occupation.append(switch_occ[i])
            occupation_remove.append(i)

    for i in switch_occ:
        for occ1 in occupation:
            if i in occ1 and not switch_occ[i] in occupation:
                occupation.append(switch_occ[i])
                occupation_remove.append(occ1)

    occupation_list=[]
    if not Human_Data["occupation"] or Human_Data["occupation"]==[u'']:
        occupation_main=[]
    else:
        occupation_main=Human_Data["occupation"]
    for i in occupation:
        i=i.replace(u'[[',u'').replace(u']]',u'')
        if not i in occupation_remove:
            occupation_list.append(i)
    for i in occupation_main:
        i=i.replace(u'[[',u'').replace(u']]',u'')
        if not i in occupation_list:
            occupation_list.append(i)
    pywikibot.output(u'*****'+u'+'.join(occupation_list))
    Human_Data["occupation"]=occupation_list
    Human_Data["occupation_safe"]=it_is_safe

    #---------university--------
    universitys=Get_box_items (my_box,[u'دانشگاه',u'alma_mate'],True)
    universitys,it_is_safe=Multy_link_clean(universitys)
    university_list=[]
    if not Human_Data["university"] or Human_Data["university"]==[u'']:
        university_main=[]
    else:
        university_main=Human_Data["university"]
    for i in universitys:
        university_list.append(i.replace(u'[[',u'').replace(u']]',u''))

    for i in university_main:
        i=i.replace(u'[[',u'').replace(u']]',u'')
        if not i in university_list:
            university_list.append(i)
    Human_Data["university"]=university_list
    Human_Data["university_safe"]=it_is_safe

    if not Human_Data["awards"] or Human_Data["awards"]==[u'']:
        awards=Get_box_items (my_box,[u'جایزه‌ها',u'جایزه',u'awards',u'جوایز',u'جوایز پولیتزر',u'جوایز نوبل',u'جایزه اریل'],True)
        awards,it_is_safe=Multy_link_clean(awards)
        Human_Data["awards"]=awards
        Human_Data["awards_safe"]=it_is_safe

    if not Human_Data["members"] or Human_Data["members"]==[u'']:
        members=Get_box_items (my_box,[u'حزب',u'party',u'جنبش',u'مکتب'],True)
        members,it_is_safe=Multy_link_clean(members)
        Human_Data["members"]=members
        Human_Data["members_safe"]=it_is_safe
    return Human_Data,my_box

def get_data_from_category (Human_Data):
    pywikibot.output(u'\03{lightblue} +++++get_data_from_category+++++\03{default}')
    # ---birth_place
    Human_Data=Find_birth_place(Human_Data,u'')
    #--- nationality
    nationality=Human_Data["nationality"]
    cat_fa_List=Human_Data["Suggested_cat_list"].replace(u':',u': ').replace(u']]',u' ]]').replace(u'[[',u'[[ ')
    if not nationality:
        for county in countries:
            fa_country=countries[county]
            if not nationality and (u' اهل '+fa_country+u' ' in  cat_fa_List or u' اهالی '+fa_country+u' ' in cat_fa_List):
                Human_Data["nationality"]=fa_country
    # ---occupation
    occupation_list=Human_Data["occupation"]
    new_list=[]
    for i in occupation_list:
        new_list.append(i.replace(u'[[',u'').replace(u']]',u'').strip())
    occupation_list=new_list
    del new_list
    fa_cats=Human_Data["Suggested_cat_list"]
    new_occ=[]
    for cat in fa_cats.split(u'\n'):
        if u' اهل ' in cat:
            first_cat=cat.replace(u'_',u' ').split(u' اهل ')[0].replace(u'رده:',u'').replace(u'[[',u'').replace(u']]',u'').strip()
            if u' ' in first_cat:
                continue
            if len(first_cat)>3:
                if first_cat[-3:]==u'گان':
                   first_cat=first_cat[:-3]+u'ه'
                elif first_cat[-2:]==u'ان':
                   first_cat=first_cat[:-2]
                elif first_cat[-3:]==u'های':
                   first_cat=first_cat[:-3]
                   if first_cat[-1]==u'‌':
                       first_cat=first_cat[:-1]
                elif first_cat[-2:]==u'ها':
                   first_cat=first_cat[:-2]
                else:
                   pass
            if not first_cat in occupation_list:
                occupation_list.append(first_cat)
                pywikibot.output(u'\03{lightgreen} + new occupation from categories! =\03{default}'+first_cat)
    Human_Data["occupation"]=occupation_list
    # ---university
    
    return Human_Data

def Multy_link_clean(txt):
    it_is_safe=True
    if u'[[' in txt:
        txt=txt.replace(u']]-[[',u']]،[[').replace(u']] - [[',u']]،[[').replace(u']] [[',u']]،[[').replace(u']][[',u']]،[[').replace(u']] و [[',u']]،[[').replace(u']]و[[',u']]،[[')
    elif u' و ' in txt:
        txt=txt.replace(u' و ',u'، ')
    else:
        pass
    RE=re.compile(ur'(\[\[.*?\]\])')
    links=RE.findall(txt)
    txt2=txt.replace(u'،',u'')
    for i in links:
       txt2=txt2.replace(i,u'')
    if txt2.strip() and not u'،[[' in txt :
       it_is_safe=True
    links2=[]
    if links:
        for i in links:
            links2.append(Find_Redirect(i))
        if links2==[u'']:
            links2=[]
        return links2,it_is_safe
    else:
        links=txt.replace(u'{{',u'').replace(u'}}',u'').split(u'،')
        if links==[u'']:
            links=[]
        if not links:
            return links2,it_is_safe
        for i in links:
            links2.append(Find_Redirect(i))
        return links2,it_is_safe


def Data2Fa(number, strict=False):
    repo = faSite.data_repository()
    try:
       Qtitle='Q'+str(number)
    except:
       Qtitle='Q'+number
    data = pywikibot.ItemPage(repo, Qtitle)
    try:
        items=data.get()
    except:
        return ""
    if isinstance(items['sitelinks'],list):
        items['sitelinks']={}

    if items['sitelinks'].has_key('fawiki'):
        return items['sitelinks']['fawiki']
    if strict:
        return ""
    if items['labels'].has_key('fa'):
        return items['labels']['fa']
    return ""

def ClaimFinder(our_Site,page_title,claim_num,more=False,Data2fas=True):
    fa_result=''
    fa_result_more=[]
    try:
        thepage=pywikibot.Page(our_Site,page_title)
        en_wdata=pywikibot.ItemPage.fromPage(thepage)
        items=en_wdata.get()
    except:
        return u''
    #pywikibot.output(str(items['claims']['P570'][0].getTarget()))
    if items['claims']:
        case=items['claims']
        for i in case:
            if i==u'P'+str(claim_num):
                if claim_num==569 or claim_num==570:
                    fa_result_main=items['claims'][u'P'+str(claim_num)][0].getTarget()
                    if fa_result_main:
                        precision=fa_result_main.toWikibase()[u'precision']
                        fa_result=fa_result_main.toWikibase()[u'time']
                        return fa_result+str(precision)
                    else:
                        continue
                our_cases=items['claims'][u'P'+str(claim_num)]
                for a in our_cases:
                    try:
                        if not Data2fas:
                            return a._formatValue()[u'numeric-id']
                        fa_result=Data2Fa(a._formatValue()[u'numeric-id'])
                    except:
                        continue
                    if not fa_result.strip():
                        continue
                    if not more:
                         break
                    else:
                        fa_result_more.append(u'[['+fa_result.strip()+u']]')

    if more and fa_result_more:
        fa_result=u' '
        lenth=len(fa_result_more)-1
        if lenth>0:
            for i in fa_result_more:
                if not re.sub(ur'[a-zA-z0-9\,\(\)\"\'\#\@\_\s\*\[\]]',u'',i).strip():
                   continue
                fa_result+=u'\n'+i
            fa_result=fa_result[2:]
        else:
            fa_result=fa_result_more[0]
    #if fa_result:
        #pywikibot.output(u'\03{lightgreen}All Claims '+str(claim_num)+u' ='+fa_result.replace(u'\n',u'-')+u'\03{default}')
    return fa_result.strip()
def Persian_sort(categorylist):
    finallradeh,s_radeh=[],[]
    alphabets=u' ۰۱۲۳۴۵۶۷۸۹آابپتثجچحخدذرزژسشصضعغفقکگلمنوهی‌'
    for radeh in categorylist:
            radeh=radeh.replace(u'[[رده:',u'').replace(u']]',u'')
            coderadeh=radeh
            for i in range(0,len(alphabets)):    
                alphabet=alphabets[i]
                if i<10:
                    j='0'+str(i)
                else:
                    j=str(i)
                coderadeh=coderadeh.replace(alphabet,j)
            s_radeh.append(coderadeh+u'0000000000000000000@@@@'+radeh)
    s_radeh=list(set(s_radeh))
    sortedradeh=sorted(s_radeh)
    for radeh in sortedradeh:
        radeh=u'[[رده:'+radeh.split(u'@@@@')[1]+u']]'
        finallradeh.append(radeh)
    return finallradeh
    
def Cat_Sorting(text,page,msg_short,msg):
    new_text=text
    RE=re.compile(u"(\[\[رده\:(?:.+?)\]\])")
    cats=RE.findall(text)
    if not cats:
        return text,msg
    for i in cats:
            new_text=new_text.replace(i,u"")
    cats=Persian_sort(cats)
    for name in cats:
        if re.search(u"\[\[(.+?)\|[ \*]\]\]",name) or u"[[رده:"+page.title()==name.split(u"]]")[0].split(u"|")[0]:
            cats.remove(name)    
            cats.insert(0, name)
    if cats==RE.findall(text):   
        return text,msg
    for i in cats:
        new_text=new_text+u"\n"+i
    new_text, cleaning_version, msg = fa_cosmetic_changes_core.fa_cosmetic_changes(new_text, page)
    if msg_short:
        msg=u'مرتب+'+msg    
    else:
        msg=u' + مرتب‌سازی رده‌ها + '+msg
    new_text=re.sub(ur'\n{3,}',u'\n\n',new_text)
    return new_text,msg

def Add_cat_to_article(total_new_cats,fa_title):
    new_cats=[]
    fapage2=pywikibot.Page(faSite,fa_title)
    fa_text2 = fapage2.get()
    fa_text2_old=fa_text2
    total_new_cats=total_new_cats.strip()
    if not total_new_cats:
        pywikibot.output(u'\03{lightred}--Bot could not find any category!\03{default}')
        return fapage2
    for i in total_new_cats.split(u'\n'):
        if (u'زادگان' in i or u'درگذشتگان' in i) and (not u'میلادی' in i) and (not 'قمری' in i):# زادگان برای مقالات فارسی باگ دارد و سال عقب و جلو می‌شود
            continue
        if (not i.strip() in new_cats) and i.strip():
            new_cats.append(i.strip())

    total_new_cats=u'\n'.join(new_cats)
    if total_new_cats.strip():
        fa_text2=fa_text2.strip()+u'\n'+total_new_cats
    new_cats_List=total_new_cats.replace(u'\n',u'▬').replace(u'[[',u'[[:')
    if len(new_cats)>3:
       new_cats_List=u'+ '+En2Fa_num(str(len(new_cats))) +u' رده '
    else:
       new_cats_List=u'+ '+new_cats_List+u' '
    msg,msg_short,msg_clean=u'',u'',u''
    fa_text2,msg=Cat_Sorting(fa_text2,fapage2,msg_short,msg)

    if fa_text2_old!=fa_text2:
        msg=u'[[وپ:ررد|ربات:رده‌دهی]] ('+version+u'): '+new_cats_List
        pywikibot.output(u'\03{lightgreen}'+msg+u'\03{default}')
        fapage2.put(fa_text2,msg)
    else:
        pywikibot.output(u'\03{lightred}--Bot could not find any category!\03{default}')
    return fapage2

def Creat_Cat(cat_per,total_new_cats,new_category,Suggested_cat_list,Check_FindFatherCat=False):
    pywikibot.output(u'? Requested cat=\03{lightblue}'+new_category+u'\03{default}')
    if u':زادگان' in new_category or u':درگذشتگان' in new_category:
        Creat_Cat_Force=True
    else:
        Creat_Cat_Force=False
    if u'[['+new_category+u']]' in Suggested_cat_list:
        return total_new_cats
    if cat_per==new_category:
        return total_new_cats
    if Check_Page_Exists(new_category) or Creat_Cat_Force:
        new_category=u'\n[['+new_category+u']]'
        total_new_cats+=new_category
    elif Check_Page_Exists(new_category.replace(u'‌',u'')):
        new_category=u'\n[['+new_category.replace(u'‌',u'')+u']]'
        total_new_cats+=new_category
    elif Check_Page_Exists(new_category.replace(u'(',u'').replace(u')',u'')):
        new_category=u'\n[['+new_category.replace(u'(',u'').replace(u')',u'')+u']]'
        total_new_cats+=new_category
    else:
        pywikibot.output(u'\03{lightyellow}Category '+new_category+u' not exist in fa.wikipedia. So it will pass!\03{default}')
        Check_FindFatherCat=False
        pass
    if Check_FindFatherCat:
        new_category=new_category.replace(u'[[',u'').replace(u']]',u'').strip()
        pywikibot.output(u'\03{lightgreen}Father Category Checking '+new_category+'\03{default}')
        if Check_Page_Exists(new_category):
            if not IsFatherCat(Suggested_cat_list,new_category):
                pywikibot.output(u'\03{lightgreen}+ '+new_category+'\03{default}')
                if not u'\n[['+new_category+u']]' in total_new_cats:
                    total_new_cats+=u'\n[['+new_category+u']]'
            else:
                total_new_cats=total_new_cats.replace(u'\n[['+new_category+u']]',u'')
        else:
            pywikibot.output(u'\03{lightyellow}Category '+new_category+u' not exist in fa.wikipedia. So it will pass!\03{default}')
    return total_new_cats

def Article_is_human_wikidtat (fapage,fa_text,Suggested_cat_list,fa_title,Human_Data):
    birth_date,death_date,birth_centry,death_centry=u'',u'',u'',u''
    death_date_pish,birth_date_pish=False,False
    gender=ClaimFinder(faSite,fa_title,21)
    nationality=ClaimFinder(faSite,fa_title,27)
    birth_date=ClaimFinder(faSite,fa_title,569)

    if birth_date:
        if birth_date[0]==u'-':
           birth_date_pish=True
        our_birth_date=birth_date[1:].split(u'-')
        birth_year=our_birth_date[0]
        birth_month=our_birth_date[1]
        birth_day=our_birth_date[2].split(u'T')[0]
        birth_precision=birth_date.split(u'Z')[1]
        if not birth_date_pish:
            birth_centry=u'سده '+str((int(birth_year)/100)+1).split(u'.')[0]+u' (میلادی)'
        else:
            birth_centry=u'سده '+str((int(birth_year)/100)+1).split(u'.')[0]+u' (پیش از میلاد)'
        birth_centry=En2Fa_num (birth_centry)
        birth_year=En2Fa_num (birth_year)
        birth_year=Normalizing_num(birth_year)
        if int(birth_precision)>8:
            birth_date=birth_year+u'-'+En2Fa_num (birth_month)+u'-'+En2Fa_num (birth_day)+u'-'+birth_precision
        else:
            birth_date,birth_centry=u'',u''

    death_date=ClaimFinder(faSite,fa_title,570)
    if death_date:
        if death_date[0]==u'-':
           death_date_pish=True
        our_death_date=death_date[1:].split(u'-')
        death_year=our_death_date[0]
        death_month=our_death_date[1]
        death_day=our_death_date[2].split(u'T')[0]
        death_precision=death_date.split(u'Z')[1]
        if not death_date_pish:
            death_centry=u'سده '+str((int(death_year)/100)+1).split(u'.')[0]+u' (میلادی)'
        else:
            death_centry=u'سده '+str((int(death_year)/100)+1).split(u'.')[0]+u' (پیش از میلاد)'
        death_centry=En2Fa_num (death_centry)
        death_year=En2Fa_num (death_year)
        death_year=Normalizing_num(death_year)
        if int(death_precision)>8:
            death_date=death_year+u'-'+En2Fa_num (death_month)+u'-'+En2Fa_num (death_day)+u'-'+death_precision
        else:
            death_date,death_centry=u'',u''

    occupation=ClaimFinder(faSite,fa_title,106,True).split(u'\n')
    birth_place=ClaimFinder(faSite,fa_title,19)
    main_category=ClaimFinder(faSite,fa_title,910)
    university=ClaimFinder(faSite,fa_title,69,True).split(u'\n')
    awards=ClaimFinder(faSite,fa_title,166,True).split(u'\n')
    members=ClaimFinder(faSite,fa_title,102,True).split(u'\n')
    members_B=ClaimFinder(faSite,fa_title,463,True).split(u'\n')

    pywikibot.output(u'---got properties---')
    pywikibot.output(u'gender=\03{lightgreen}'+gender+u'\03{default}')
    pywikibot.output(u'nationality=\03{lightgreen}'+nationality+u'\03{default}')
    if not birth_date_pish:
        pywikibot.output(u'birth_date=\03{lightgreen}'+birth_date+u'\03{default}')
        pywikibot.output(u'birth_centry=\03{lightgreen}'+birth_centry+u'\03{default}')
    else:
        pywikibot.output(u'birth_date=\03{lightgreen}'+birth_date+u' BC\03{default}')
        pywikibot.output(u'birth_centry=\03{lightgreen}'+birth_centry+u'\03{default}')
    if not death_date_pish:
        pywikibot.output(u'death_date=\03{lightgreen}'+death_date+u'\03{default}')
        pywikibot.output(u'death_centry=\03{lightgreen}'+death_centry+u'\03{default}')
    else:
        pywikibot.output(u'death_date=\03{lightgreen}'+death_date+u' BC\03{default}')
        pywikibot.output(u'death_centry=\03{lightgreen}'+death_centry+u'\03{default}')
    pywikibot.output(u'occupation=\03{lightgreen}'+u'-'.join(occupation)+u'\03{default}')
    pywikibot.output(u'birth_place=\03{lightgreen}'+birth_place+u'\03{default}')
    pywikibot.output(u'main_category=\03{lightgreen}'+main_category+u'\03{default}')
    pywikibot.output(u'university=\03{lightgreen}'+u'-'.join(university)+u'\03{default}')
    pywikibot.output(u'awards=\03{lightgreen}'+u'-'.join(awards)+u'\03{default}')
    pywikibot.output(u'members=\03{lightgreen}'+u'-'.join(members)+u'\03{default}')
    pywikibot.output(u'members_B=\03{lightgreen}'+u'-'.join(members_B)+u'\03{default}')

    if not Suggested_cat_list.strip():
       Suggested_cat_list=u'\n'
    if Human_Data[u"gender"]:
        gender=Human_Data[u"gender"]
    Human_Data["Suggested_cat_list"]=Suggested_cat_list
    Human_Data["gender"]=gender
    Human_Data["nationality"]=nationality
    Human_Data["birth_date"]=birth_date
    Human_Data["birth_centry"]=birth_centry
    Human_Data["death_date"]=death_date
    Human_Data["death_centry"]=death_centry
    Human_Data["occupation"]=occupation
    Human_Data["birth_place"]=birth_place
    Human_Data["main_category"]=main_category
    Human_Data["university"]=university
    Human_Data["awards"]=awards
    Human_Data["members"]=members
    Human_Data["members_B"]=members_B
    Human_Data["birth_date_pish"]=birth_date_pish
    return Human_Data

def Category_for_human (Human_Data):
    Suggested_cat_list=Human_Data["Suggested_cat_list"]
    gender=Human_Data["gender"]
    nationality=Human_Data["nationality"]
    birth_date=Human_Data["birth_date"]
    birth_date_fa=Human_Data["birth_date_fa"]
    birth_centry=Human_Data["birth_centry"]
    death_date=Human_Data["death_date"]
    death_date_fa=Human_Data["death_date_fa"]
    death_centry=Human_Data["death_centry"]
    occupation=Human_Data["occupation"]
    birth_place=Human_Data["birth_place"]
    main_category=Human_Data["main_category"]
    university=Human_Data["university"]
    awards=Human_Data["awards"]
    members=Human_Data["members"]
    members_B=Human_Data["members_B"]
    birth_date_pish=Human_Data["birth_date_pish"]
    death_date_pish=birth_date_pish
    if nationality:
        pywikibot.output(u'nationality=\03{lightgreen}'+nationality+u'\03{default}')
    #----------------------temprary--------------------
    #Suggested_cat_list=u''
    #--------------------------------------------------
    #-------------------------------------------------------todo--------------------------------------
    Date_could_be_jalaly=False
    if u'-' in death_date:
        if int(death_date.split(u'-')[0])>1600 and not death_date_pish:#jalaly existed after this year
            Date_could_be_jalaly=True
        
    if u'-' in birth_date and not Date_could_be_jalaly and not birth_date_pish:
        if int(birth_date.split(u'-')[0])>1600:#jalaly existed after this year
            Date_could_be_jalaly=True

    if (nationality==u'ایران' or nationality==u'افغانستان' or nationality==u'تاجیکستان') and Date_could_be_jalaly:
        if  u'-' in death_date:
            death_year,death_month,death_day=death_date.split(u'-')[0],death_date.split(u'-')[1],death_date.split(u'-')[2]
            death_year_fa,death_month_fa,death_day_fa=cal.jd_to_jalali(cal.gregorian_to_jd(int(Fa2En_num (death_year)), int(death_month), int(death_day)))
            death_centry=u'سده '+En2Fa_num(str((death_year_fa/100)+1).split(u'.')[0])
            death_year_fa=En2Fa_num (death_year_fa)
            death_date=death_year_fa+u'-'+str(death_month_fa)+u'-'+str(death_day_fa)+u'--fa'
        else:
            death_date=u''
        if  u'-' in birth_date:
            birth_year,birth_month,birth_day=birth_date.split(u'-')[0],birth_date.split(u'-')[1],birth_date.split(u'-')[2]
            birth_year_fa,birth_month_fa,birth_day_fa=cal.jd_to_jalali(cal.gregorian_to_jd(int(Fa2En_num (birth_year)), int(birth_month), int(birth_day)))
            birth_centry=u'سده '+En2Fa_num(str((birth_year_fa/100)+1).split(u'.')[0])
            birth_year_fa=En2Fa_num (birth_year_fa)
            birth_date=birth_year_fa+u'-'+str(birth_month_fa)+u'-'+str(birth_day_fa)+u'--fa'
        else:
            birth_date=u''
    else:
        if  u'-' in birth_date:
            birth_date+=u'-en'
        if  u'-' in death_date:
            death_date+=u'-en'
    if birth_date_fa:
        birth_date=birth_date_fa+u'----'
    if death_date_fa:
        death_date=death_date_fa+u'----'
    if death_date:
        pywikibot.output(u'death_date for cat=\03{lightgreen}'+death_date+u'\03{default}')
    if birth_date:
        pywikibot.output(u'birth_date for cat=\03{lightgreen}'+birth_date+u'\03{default}')
    #-------------------------------------------------------------------------------------------------
    pywikibot.output(u'********************\03{lightblue}Requesting Cat\03{default}********************************')
    total_new_cats=u'\n'
    Suggested_cat_list2=Suggested_cat_list.replace(u'رده:',u'رده: ').replace(u'[[',u'[[ ').replace(u']]',u' ]]')

    if u'-' in birth_date and u'-' in death_date:
        age=int(death_date.split(u'-')[0]) - int(birth_date.split(u'-')[0])
        if Fa2En_num(age) <15 and not birth_date_pish:
            birth_date,death_date=u'',u''
            Human_Data["birth_date"]=u''
            Human_Data["birth_centry"]=u''
            Human_Data["death_date"]=u''
            Human_Data["death_centry"]=u''
            total_new_cats+=u'\n[[رده:مقاله‌های دارای تاریخ تولد و مرگ نادرست]]'
            pywikibot.output(u'\03{lightred}Death_date and Birth_date are not correct! The age='+str(age)+u' \03{default}')
    MakeCat=True
    if not u' زادگان ' in Suggested_cat_list2.replace(u'زادگان سده',u''):
        if u'-' in birth_date:
            birth_year=birth_date.split(u'-')[0].strip()
            if birth_year:
                if birth_date.split(u'-')[4]==u'en':
                    birth_extend=u' (میلادی)'
                else:
                    birth_extend=u''
                    if int(Fa2En_num (birth_year))>1400:
                        pywikibot.output(u'\03{lightred}>>>>Jalaly Year is more than 1400='+birth_year+u' \03{default}')
                        MakeCat=False
                        birth_centry=u''
                        Human_Data["birth_date"]=u''
                        Human_Data["birth_centry"]=u''
                if MakeCat:
                    if not birth_date_pish:
                        new_category=u'رده:زادگان '+birth_year+birth_extend
                    else:
                        new_category=u'رده:زادگان '+birth_year+u' (پیش از میلاد)'
                    total_new_cats=Creat_Cat(u'رده:ناموجود۱',total_new_cats,new_category,Suggested_cat_list)
    MakeCat=True
    if not u' درگذشتگان ' in Suggested_cat_list2.replace(u'درگذشتگان سده',u''):
        if u'-' in death_date:
            death_year=death_date.split(u'-')[0].strip()
            if death_year:
                if death_date.split(u'-')[4]==u'en':
                    death_extend=u' (میلادی)'
                else:
                    death_extend=u''
                    if int(Fa2En_num (death_year))>1400:
                        pywikibot.output(u'\03{lightred}>>>>Jalaly Year is more than 1400='+death_year+u' \03{default}')
                        MakeCat=False
                        death_centry=u''
                        Human_Data["death_date"]=u''
                        Human_Data["death_centry"]=u''
                if MakeCat:
                    if not death_date_pish:
                        new_category=u'رده:درگذشتگان '+death_year+death_extend
                    else:
                        new_category=u'رده:درگذشتگان '+death_year+u' (پیش از میلاد)'
                    total_new_cats=Creat_Cat(u'رده:ناموجود۱',total_new_cats,new_category,Suggested_cat_list)
        
    cat_gender=''
    if gender==u'مذکر':
        cat_gender=u'مرد'
    if gender==u'مؤنث':
        cat_gender=u'زن'

    if nationality:
        if  occupation:
            for i in occupation:
                i=i.replace(u'سیاستمدار',u'سیاست‌مدار')
                i=i.replace(u'[[',u'').replace(u']]',u'').strip()
                if i in trans_occ:
                    occu=trans_occ[i]
                else:
                    if i.strip():
                        if u' ' in i:
                            first_part=i.split(u' ')[0]
                            second_part=i.split(first_part)[1]
                            occu=first_part+u'ان '+second_part
                        else:
                            occu=i+u'ان'
                    else:
                       continue
                if cat_gender:
                    new_category=u'رده:'+occu+u' '+cat_gender+u' اهل '+nationality
                else:
                    new_category=u'رده:ناموجود۱'
                new_cats1=total_new_cats
                total_new_cats=Creat_Cat(u'رده:ناموجود۱',total_new_cats,new_category,Suggested_cat_list)
                if new_cats1==total_new_cats:
                    if not new_category in Suggested_cat_list:
                        new_category=u'رده:'+occu+u' اهل '+nationality
                        total_new_cats=Creat_Cat(u'رده:',total_new_cats,new_category,Suggested_cat_list,True)#-------
                if birth_centry:
                    new_category=u'رده:'+occu+u' '+birth_centry+u' اهل '+nationality
                    total_new_cats=Creat_Cat(u'رده:',total_new_cats,new_category,Suggested_cat_list,True)
                if death_centry and death_centry!=birth_centry:
                    new_category=u'رده:'+occu+u' '+death_centry+u' اهل '+nationality
                    total_new_cats=Creat_Cat(u'رده:',total_new_cats,new_category,Suggested_cat_list)

            if  u'سیاست‌مدار' in occupation and (u'پدیدآور' in occupation or u'نویسنده' in occupation):
                    new_category=u'رده:نویسندگان سیاسی اهل '+nationality
                    total_new_cats=Creat_Cat(u'رده:نویسندگان سیاسی اهل ',total_new_cats,new_category,Suggested_cat_list)
    if birth_place:
            his_place=birth_place
    else:
        if nationality:
            his_place=nationality
        else:
            his_place=u''
    if his_place:
        if not his_place in total_new_cats and not u' '+his_place+u' ' in Suggested_cat_list2:
            new_category=u'رده:اهالی '+his_place
            total_new_cats=Creat_Cat(u'رده:اهالی ',total_new_cats,new_category,Suggested_cat_list,True)#-------
    if university:
        for i in university:
            new_category=u'رده:دانش‌آموختگان '+i.replace(u'[[',u'').replace(u']]',u'').strip()
            total_new_cats=Creat_Cat(u'رده:دانش‌آموختگان ',total_new_cats,new_category,Suggested_cat_list)
    if awards:
        for i in awards:
            new_category=u'رده:برندگان '+i.replace(u'[[',u'').replace(u']]',u'').strip()
            total_new_cats=Creat_Cat(u'رده:برندگان ',total_new_cats,new_category,Suggested_cat_list)
    if members:
        for i in members:
            new_category=u'رده:اعضای '+i.replace(u'[[',u'').replace(u']]',u'').strip()
            total_new_cats=Creat_Cat(u'رده:اعضای ',total_new_cats,new_category,Suggested_cat_list)
    if members_B:
        for i in members_B:
            new_category=u'رده:اعضای '+i.replace(u'[[',u'').replace(u']]',u'').strip()
            total_new_cats=Creat_Cat(u'رده:اعضای ',total_new_cats,new_category,Suggested_cat_list)

    total_new_cats=total_new_cats.replace(u'  ',u' ')
    if main_category:
        if not main_category in Suggested_cat_list:
            total_new_cats+=u'\n[['+main_category+u']]'
    return total_new_cats,Suggested_cat_list

def Check_is_human(fa_title,Suggested_cat_list):
    Suggested_cat_list=Suggested_cat_list.replace(u'(',u' ( ').replace(u')',u' ) ').replace(u'،',u' ، ').replace(u':',u' : ').replace(u']]',u' ]]').replace(u'[[',u'[[ ')
    title_black_list=[u'بین‌الملل',u'فهرست',u'قوم',u'اقوام',u'مردم',u'اهالی',u'برادر',u'خواهر',u'گروه',u'دسته',
                 u'بنیاد',u'سازمان',u'اپیزود',u'فیلم',u'جوامع',u'جامعه',u'ایلات',u'استان',u'ایالت',u'کشور']
    cat_black_list=[u'رده:جغرافیای ',u'رده:کشور',u'رده:آثار',u'رده:استان',u'رده:شهر',u'رده:دهستان',u'رده:روستا',
                    u'رده:ایالت',u'رده:انحلال',u'رده:تاسیس',u'رده:تخریب',u'رده:منطقه‌های',u'رده:مردمان',u'رده:اقوام',u'رده:گروه',
                    u'رده:جامعه ',u'رده:ایلات',u'رده:آسیا',u'رده:اروپا',u'رده:آمریکا',u'رده:آفریقا',u'رده:جوامع',u'رده:ایل‌های',
                    u'رده:تاریخ ']
    fa_num_and_en=u'۰۱۲۳۴۵۶۷۸۹0123456789qwertyuiopasdfghjklzxcvbnm'

    if len(fa_title.split(u' '))!=2:
            pywikibot.output(u'>>\03{lightred}Title is not 2 part! So it is not human\03{default}')
            return False

    for b in cat_black_list:
        if b in Suggested_cat_list:
            pywikibot.output(u'>>\03{lightred}Category_Black_list is activated! So it is not human\03{default}')
            return False

    title_first_part=fa_title.split(u'(')[0]
    for i in fa_num_and_en:
        if i in title_first_part.lower():
            pywikibot.output(u'>>\03{lightred}Title has wrong charcters! So it is not human\03{default}')
            return False

    for i in title_black_list:
        if i in fa_title:
            pywikibot.output(u'>>\03{lightred}Title black list is activated! So it is not human\03{default}')
            return False

    return True

def Find_articles_topic(object_type,fa_text,Suggested_cat_list,fa_title):
    Suggested_cat_list=Suggested_cat_list.replace(u'(',u' ( ').replace(u')',u' ) ').replace(u'،',u' ، ').replace(u':',u' : ').replace(u']]',u' ]]').replace(u'[[',u'[[ ')
    gender=None
    fa_title=fa_title.replace(u'_',u' ')
    stub_temps=[u"آهنگساز",u"اتومبیل‌ران_فرمول_۱",u"اتوموبیل‌ران_فرمول_۱",u"افراد-انگلستان",u"افراد",u"اقتصاددان",
               u"اندیشمند",u"بازیکن_فوتبال",u"بازیکنان_فوتبال",u"بازیگر",u"بازیگر-پورنو",u"بازیگر_سینما",u"تاریخ‌دان",u"خواننده",
               u"دانشمند",u"دانشمندان",u"داور",u"ریاضیدان",u"زبان‌شناس",u"زندگینامه",u"زندگینامه_اهالی_ایران",u"زندگینامه_اهالی_سوریه",
               u"زندگینامه_ایرانی",u"زندگینامه_مسلمان",u"سیاستمدار",u"سیاستمدار_ایرانی",u"سیاستمدار_ژاپنی",u"سیاستمداران",u"شخصیت_ورزشی",
               u"فضانورد",u"فضانوردان",u"فوتبالیست",u"فوتبالیست_انگلستان",u"فیزیک‌دان",u"فیلسوف",u"مخترع",u"معمار",u"مهندس",u"مهندسان",
               u"موسیقی_دان",u"موسیقی‌دان",u"نقاش",u"نماینده_مجلس_شورای_اسلامی",u"نوازنده",u"نویسنده",u"نویسندگان",u"پادشاه",u"کارگردان",u"کشتی‌گیر"]
    person_cat_words=[u'نخست‌وزیران',u'مسئولان روابط عمومی‎',u'درگذشتگان‎',u'زادگان‎',u'اهالی ',u'نمایندگان',u'بازیگران',u'بازیکنان',u'سیاست‌مدار']
    if not object_type:
        if not Check_is_human(fa_title,Suggested_cat_list):
            return object_type,gender

    if not object_type:
        for i in person_cat_words:
            if i in Suggested_cat_list:
                object_type=u'انسان'
                break
    if not object_type:
        for i in stub_temps:
            if u'{{'+ i+u'-خرد}}' in fa_text or u'{{'+ i.replace(u'_',u' ')+u'-خرد}}' in fa_text :
                object_type=u'انسان'
    first_name=fa_title.replace(u'‌',u' ').split(u' ')[0]
    if object_type:
        if u' مرد ' in Suggested_cat_list or u' مردان ' in Suggested_cat_list:
            gender=u'مذکر'
        if not gender:
            if u' زن ' in Suggested_cat_list or u' زنان ' in Suggested_cat_list:
                gender=u'مؤنث'
        if not gender:
            for i in Male_Names:
                if u' '+i+u' ' in u' '+first_name+u' ':
                    gender=u'مذکر'
                    break
        if not gender:
            for i in Femail_names:
                if u' '+i+u' ' in u' '+first_name+u' ':
                    gender=u'مؤنث'
                    break
    return object_type,gender

def Wright_file(Human_Data,my_box):
    file=Url+u'people_item_property.txt'
    file2=Url+u'people_item_property-2.txt'
    file_text=u'\n'
    old_file_text=file_text
    try:        
        file_text = codecs.open(file2,'r' ,'utf8' )
        file_text = file_text.read()
    except:
        file_text=u'\n'
    file_line=u'.\t'
    for i in Human_Data:
        if i=="birth_date_pish" or i=="main_category" or i=="occupation_safe" or i=="university_safe" or i=="awards_safe" or i=="members_safe":
            continue
        try:
            a=Human_Data[i]+u'a'
            print_text=i+u' >'+Human_Data[i].replace(u'\n',u'، ')
        except:
            if Human_Data[i]!=False and Human_Data[i]!=True:
                print_text=i+u' >'+u'،'.join(Human_Data[i])
            else:
                print_text=i+u' >'+u' '
        file_line+=print_text+u'\t'
    file_text+=u'\n----------------'+Human_Data['#Article_name'].replace(u' ',u'_')+'-----------------\n'
    file_text+=file_line
    file_line=file_line.replace(u'\t، \t',u'\t\t').replace(u'، ،',u'،').replace(u'\t، ',u'\t').replace(u'، \t',u'\t')
    file_line=file_line.replace(u'،\t',u'\t').replace(u'{{\n\n}}\n',u'').replace(u'{{\n\n}}',u'').replace(u'\n\n',u'\n')

    file_text=file_text.replace(u'\t، \t',u'\t\t').replace(u'، ،',u'،').replace(u'\t، ',u'\t').replace(u'، \t',u'\t')
    file_text=file_text.replace(u'،\t',u'\t').replace(u'{{\n\n}}\n',u'').replace(u'{{\n\n}}',u'').replace(u'\n\n',u'\n')
    try:        
        file_text2 = codecs.open(file,'r' ,'utf8' )
        file_text2 = file_text2.read()
    except:
        file_text2=u'\n'
    if not file_line in file_text2:
        with codecs.open(file ,mode = 'a',encoding = 'utf8' ) as f:
                            f.write(file_line)
    file_text=file_text.replace(u'\t',u'\n').replace(u'\n\n\n',u'\n').replace(u'\n\n',u'\n').replace(u'\n\n',u'\n').replace(u'\n\n',u'\n').replace(u'.\n',u'')
    file_text+=u'\n++++++++\n'+my_box+u'\n'
    if not file_line in file_text:
        with codecs.open(file2 ,mode = 'w',encoding = 'utf8' ) as f:
                            f.write(file_text)

def Human_Data_cleaner(Human_Data,my_box):
    for i in Human_Data:
        if Human_Data[i]:
            if Human_Data[i]==[u'']:
                Human_Data[i]=u''
                continue
            try:
                Human_Data[i]=Human_Data[i].strip()
                if Human_Data[i]==u'(میلادی)' or Human_Data[i]==u'(پیش از میلاد)':
                    Human_Data[i]=u''
            except:
                pass
        else:
            Human_Data[i]=u''
    for a in [u"occupation","university","awards","members"]:
        new_list=[]
        for i in Human_Data[a]:
            if not i in new_list:
                new_list.append(i)
        Human_Data[a]=new_list

    if my_box:
        for i in Human_Data:
            if i=='Suggested_cat_list' or i=="birth_date_pish" or i=="#Article_name":
                continue
            try:
                a=Human_Data[i]+u'a'
                print_text=Human_Data[i]
            except:
                if Human_Data[i]!=False and Human_Data[i]!=True:
                    print_text=u'،'.join(Human_Data[i])
                else:
                    print_text=u' '
            pywikibot.output(i+u'=\03{lightpurple}'+print_text+u'\03{default}')
    pywikibot.output(u'Existing cat: '+Human_Data["Suggested_cat_list"].replace(u'\n',u'-'))
    return Human_Data

def SubCatQuery(CatName):
    pywikibot.output(u'....CatSubQuery= '+CatName)
    cats=[]
    CatName=CatName.replace(u' ',u'_')    
    try:
        categoryname = pywikibot.data.api.Request(site=faSite, action="query", list="categorymembers",cmtitle=CatName,cmtype='subcat',cmlimit=500)
        categoryname=categoryname.submit()
        for item in categoryname[u'query'][u'categorymembers']:
            categoryha=item[u'title']
            cats.append(categoryha)
        if cats!=[]:    
            return cats
    except:
        return []

def Find_Redirect( page_link):
    page_link=page_link.replace(u' ',u'_').replace(u'[[',u'').replace(u']]',u'').replace(u'{{',u'').replace(u'}}',u'')
    try:
        query_page = pywikibot.data.api.Request(site=faSite, action="query", redirects="",titles=page_link)
        query_page=query_page.submit()
        redirect_link=query_page[u'query'][u'redirects'][0]['to']
        try:
           hashpart=query_page[u'query'][u'redirects'][0]['tofragment']
           return page_link.replace(u'_',u' ')
        except:
            pywikibot.output(u'--->\03{lightblue}Redirect '+page_link+u'\03{default} > \03{lightgreen}'+redirect_link+u'\03{default}')
            return redirect_link
    except:
        return page_link.replace(u'_',u' ')

def IsFatherCat(Suggested_cat_list,new_category):#kol,#ezafeh
    FatherCatDict={u'سیاست‌مداران':[u'نمایندگان',u'وزیران',u'رئیس‌جمهور']}
    for cat in FatherCatDict:
        for item in FatherCatDict[cat]:
            if  (cat in new_category or cat.replace(u'‌',u'') in new_category) and item in Suggested_cat_list:
                return True
    Suggested_cat_list=Suggested_cat_list.replace(u'[[',u'').replace(u']]',u'')
    Suggested_cat_list=Suggested_cat_list.split('\n')
    counters=0
    listacategory=[new_category]
    for i in Suggested_cat_list:
        if u'مقاله‌ها' in i:
            Suggested_cat_list.remove(i)

    if Suggested_cat_list:
        for title in listacategory:
            counters+=1
            if title in Suggested_cat_list:
                return True
            if counters>150:
                return False
            gencat=SubCatQuery(title)
            if not gencat:
                pywikibot.output(u'Sleep for 5 sec')
                time.sleep(5)
                gencat=SubCatQuery(title)
            if not gencat:
                pywikibot.output(u'The '+title+u' is passed')
                continue
            if len(gencat)>150:
                pywikibot.output(u'The '+title+u' is passed')
                continue
            for title2 in gencat:
                if not title2 in listacategory:
                    if title2 in Suggested_cat_list:
                        return True
                    listacategory.append(title2)
    return False

def Run(preloadingGen,Since_Page,hasnew,Qfile):
    new_counter=0
    for fapages in preloadingGen:
        if Qfile:
            number=fapages.title().replace(u'Q',u'')
            fatitle1=Data2Fa(number, strict=True)
            #pywikibot.output(u"Starting with "+fatitle1)
        else:
            fatitle1=fapages.title()

        if not fatitle1:
            continue
        if hasnew:
            new_counter+=1
            if new_counter<1000:
                continue
            else:
                hasnew=False
                pywikibot.output(u"Starting new pages after "+str(new_counter))
        #if True:
        try:
            my_box,fa_text,Human_Data,object_type,fa_text,fa_title,Total_new_cats,fa_cats=u'',u'',u'',u'',u'',u'',u'',u''
            Suggested_cat_list,gender=u'\n',u''
            
            fapage=pywikibot.Page(faSite,fatitle1)
            try:
                fa_text=fapage.get()
            except pywikibot.IsRedirectPage:
                pywikibot.output(u"The page %s is a redirect, going to get target page." % fapage.title())    
                fapage=fapage.getRedirectTarget()
                try:
                    fa_text=fapage.get()
                except:
                    pywikibot.output(u"The page %s doesn't exist, skip!" % fapage.title())
                    continue
            except:
                pywikibot.output(u"The page %s doesn't exist, skip!" % fapage.title())
                continue
            fa_cats=fapage.categories()
            fa_title=fapage.title()
            #-------Since title for -cat argument -----------
            if Since_Page:
                if fa_title!=Since_Page:
                    continue
                else:
                    Since_Page=False
            #-------Black List Template query-----------
            fa_temps=templatequery(fa_title)
            Pass_Page=True
            for fa_tem in fa_temps:
                if fa_tem in Temp_black_list:
                    Pass_Page=False
                    break
            if not Pass_Page:
                pywikibot.output(u'The page \03{lightblue}'+fa_title.replace(u' ',u'_')+u'\03{default} has Black_list template so it will be pass!')
                continue
            pywikibot.output(u'*************************\03{lightblue}'+fa_title.replace(u' ',u'_')+u'\03{default}*****************************') 
            
            for i in fa_cats:
               Suggested_cat_list+=u'[['+i.title().split(u'|')[0].replace(u'[[',u'').replace(u']]',u'').strip()+u']]\n'
            sub_group=False
            sub_group=ClaimFinder(faSite,fa_title,279)
            if sub_group:
                pywikibot.output(u'\03{lightred}This bot only support human topice\03{default}')
                continue
            object_type=ClaimFinder(faSite,fa_title,31)
            if object_type:
                if object_type!=u'انسان':
                    pywikibot.output(u'\03{lightred}This bot only support human topice.\03{default} object_type=> '+object_type+u' ')
                    continue
            object_type,gender=Find_articles_topic(object_type,fa_text,Suggested_cat_list,fa_title)
            if not object_type:
                    pywikibot.output(u'\03{lightred}Bot could not find articles topic\03{default}')
                    continue
            Human_Data={u'#Article_name':fa_title,u"Suggested_cat_list":u'',u"gender":gender, u"nationality":u'',u"birth_date":u'',u"birth_centry":u'', u"death_date":u'',
                    u"death_centry":u'',u"occupation":u'',u"birth_place":u'',u"main_category":u'',u"university":u'',u"awards":u'',u"members":u'',
                    u"members_B":u'',u"birth_date_pish":u'',"birth_date_fa":u"","death_date_fa":u"","occupation_safe":u'' ,"university_safe":u'' ,"awards_safe":u'' ,"members_safe":u'',}
            if object_type==u'انسان':
                Human_Data=Article_is_human_wikidtat (fapage,fa_text,Suggested_cat_list,fa_title,Human_Data)
                Human_Data,my_box=Article_is_human_box (fa_text,Human_Data)
                Human_Data=get_data_from_category (Human_Data)
                Human_Data=Human_Data_cleaner(Human_Data,my_box)
                Human_Data['newcat']=u''
                Total_new_cats,Suggested_cat_list=Category_for_human (Human_Data)
                pywikibot.output(u'New cat:\03{lightred} '+Total_new_cats+u'\03{default}')
                Human_Data['newcat']=Total_new_cats
                fapage=Add_cat_to_article(Total_new_cats,fa_title)
                Add_property_to_wikidata(fapage,Human_Data)
            else:
                pywikibot.output(u'\03{lightred}This bot only support human topice\03{default}')
            del my_box,Human_Data,object_type,fa_text,gender,Suggested_cat_list,fa_title,Total_new_cats,fapage,fa_cats
        except Exception as e: 
            #pywikibot.output(u'\03{lightred}!!!!!‌Bot will Try the next page!!!!!!> '+str(e)+'\03{default}')
            continue
def main():
    PageTitles=[]
    hasnew=False
    gen,namespaces,preloadingGen='','',''
    Since_Page=False
    Qfile=False
    genFactory = pagegenerators.GeneratorFactory()
    for arg in pywikibot.handleArgs():
        if arg.startswith('-new'):    
            arg=arg.replace(':','')
            if len(arg) == 4:
                genfa = pagegenerators.NewpagesPageGenerator(step=200)
            else:
                genfa = pagegenerators.NewpagesPageGenerator(step=int(arg[4:]))
            
            preloadingGen = pagegenerators.PreloadingGenerator( genfa,50)
            hasnew=True
            break
        elif arg.startswith('-page'):
            if len( arg ) == 5:
                PageTitles.append( pywikibot.input(u'Which page do you want to chage?') )    
            else:
                PageTitles.append( arg[6:] )
            break
        elif arg.startswith('-namespace:'):
            namespaces=int(arg[11:])
        elif arg.startswith('-since:'):
            Since_Page=arg[7:].replace(u'_',u' ').strip()
            pywikibot.output(u'\03{lightblue}Since=\03{default}'+Since_Page)
        elif arg.startswith('-file'):
            textfilename = arg[6:]
            if not textfilename:
                textfilename = pywikibot.input(
                    u'Please enter the local file name:')
            gen = pagegenerators.TextfilePageGenerator(textfilename,site=faSite)
        elif arg.startswith('-Qfile'):
            textfilename = arg[7:]
            if not textfilename:
                textfilename = pywikibot.input(
                    u'Please enter the local file name:')
            gen = pagegenerators.TextfilePageGenerator(textfilename,site=faSite)
            Qfile=True
        elif arg.startswith('-start'):
            firstPageTitle = arg[7:]
            if not firstPageTitle:
                firstPageTitle = pywikibot.input(u'At which page do you want to start?')
            firstpagelink = pywikibot.Link(firstPageTitle)
            firstPageTitle = firstpagelink.title
            preloadingGen = pagegenerators.AllpagesPageGenerator(firstPageTitle, namespace=0,includeredirects=False)
        elif arg.startswith('-cat'):
            gen = genFactory.getCategoryGen(arg, len('-cat'))
        else:
            generator = genFactory.handleArg( arg )
            if generator:
                gen = generator
    if not gen:
        pywikibot.stopme()    
    if PageTitles:
        pages = [pywikibot.Page( faSite,PageTitle ) for PageTitle in PageTitles]
        gen = iter( pages )
    if namespaces:
        gen = pagegenerators.NamespaceFilterPageGenerator( gen,namespaces )
    if not preloadingGen:
        preloadingGen = pagegenerators.PreloadingGenerator( gen,step = 500)
    Run(preloadingGen,Since_Page,hasnew,Qfile)
        
if __name__ == "__main__":
    pywikibot.output(u'\03{lightpurple}      *******************************\03{default}')  
    pywikibot.output(u'\03{lightpurple}      *     Code version is '+version+u'    *\03{default}')
    pywikibot.output(u'\03{lightpurple}      *******************************\03{default}')      
    main()  